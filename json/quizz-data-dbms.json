{

	"Systems": "SECTION",
	"Systems - Principles - Consistency": ".",
	"Systems - Principles - Consistency - Strong": "Strong consistency is a consistency model where all subsequent accesses to a distributed system will always return the updated value after the update.",
	"Systems - Principles - Consistency - Weak": "It is a consistency model used in distributed computing where subsequent accesses might not always be returning the updated value. There might be inconsistent responses.",
	"Systems - Principles - Consistency - Eventual": "Eventual consistency is a special type of weak consistency method which informally guarantees that, if no new updates are made to a given data item, eventually all accesses to that item will return the last updated value.",
	"Systems - Principles - HA - Scalability": "",
	"Systems - Principles - HA - Scalability - Dimensions": "In their book â€œThe Art of Scalability,â€ Martin Abbott and Michael Fisher elaborate on the concept of the â€œscale cube,â€. (X) Each service can then be further scaled by cloning (X-axis), (Y) The microservices pattern maps to the Y-axis of the cube, wherein functional decomposition is used to scale the system (Z) sharding (Z-axis).",
	"Systems - Principles - HA - Scalability - ScaleCube - X - clone services (horizontal duplication)": "X-axis scaling consists of running multiple copies of an application behind a load balancer. If there are N copies then each copy handles 1/N of the load. This is a simple, commonly used approach of scaling an application. One drawback of this approach is that because each copy potentially accesses all of the data, caches require more memory to be effective. Another problem with this approach is that it does not tackle the problems of increasing development and application complexity.",
	"Systems - Principles - HA - Scalability - ScaleCube - y - microservices (functional decomposition)": "Unlike X-axis and Z-axis, which consist of running multiple, identical copies of the application, Y-axis axis scaling splits the application into multiple, different services. Each service is responsible for one or more closely related functions. There are a couple of different ways of decomposing the application into services. One approach is to use verb-based decomposition and define services that implement a single use case such as checkout. The other option is to decompose the application by noun and create services responsible for all operations related to a particular entity such as customer management. An application might use a combination of verb-based and noun-based decomposition.",
	"Systems - Principles - HA - Scalability - ScaleCube - z - sharding databases (data partioning)": "When using Z-axis scaling each server runs an identical copy of the code. In this respect, itâ€™s similar to X-axis scaling. The big difference is that each server is responsible for only a subset of the data. Some component of the system is responsible for routing each request to the appropriate server. One commonly used routing criteria is an attribute of the request such as the primary key of the entity being accessed. Another common routing criteria is the customer type. For example, an application might provide paying customers with a higher SLA than free customers by routing their requests to a different set of servers with more capacity.",
	"Systems - Theorems - Distributed - CAP Theorem ": "In any distributed data store, you can have at most two of these three properties: consistency (C), high availability (A), tolerance to network partitions (P)",
	"Systems - Theorems - Distributed - CAP Theorem - Consistency (C)": "Consistency (C) â€“ Every read receives the most recent write or an error.",
	"Systems - Theorems - Distributed - CAP Theorem - Availability (A)": "Availability (A) â€“ Every request (read/write) gets a response, even if it's not the most recent data.",
	"Systems - Theorems - Distributed - CAP Theorem - PartitionTolerance (P)": "Partition Tolerance (P) â€“ The system continues operating despite network failures between nodes.",
	"Systems - Theorems - Distributed - CAP Theorem - Solutions - CA - Forfeit Partitions": "The system achieves High Available Consistency. To manage data across multiple resources these systems used methods like 2-Phase Commit. Single-site databases, RDBMS (Oracle, Postgres, MySQL) could be good eamples of CA systems.",
	"Systems - Theorems - Distributed - CAP Theorem - Solutions - CP - Best Effort Availity": "The system achieves Strong Consistency with Partition Tolerance. Pessimistic Locking methods used for multi resource data management. DNS, MongoDB, HBase, Redis are the example CP systems.",
	"Systems - Theorems - Distributed - CAP Theorem - Solutions - AP - Best Effort Consistency": "The system offers Full Availability by relaxing consistency. Optimistic Locking methods used for multi resource data management. CouchBase, Cassandra, DynamoDB, Hazelcast are the example CP systems.",
	"Systems - Theorems - Decentralized - DCS Theorem": "",
	"Systems - Theorems - Decentralized - DCS Theorem - Decentralization": "Decentralized means the system has no single point of failure or control (SPoF). Another way to state this is: if any single element is removed from {ğ‘†}, the system continues to perform its intended behavior, and no single component in {ğ‘†} has the power to redefine ğ‘“ğ‘† on its own.",
	"Systems - Theorems - Decentralized - DCS Theorem - Consensus": "Consensus means the system uses a collective decision-making process ('consensus algorithm') to update the systemâ€™s state, ğ‘ , which is shared by all consensus participants. The result of the consensus algorithm determines the networkâ€™s accepted output of ğ‘“ğ‘† , and whether or not ğ‘“ğ‘† completes within ğ‘†ğœ.",
	"Systems - Theorems - Decentralized - DCS Theorem - Scalability": "Scale means the system is capable of handling the transactional demands of any competing system providing the same service to the same arbitrary set of users across the globe (â€œat scaleâ€).2",

	"Caching": "SECTION",
	"Caching - Eviction - LRU": "ğ‹ğğšğ¬ğ­ ğ‘ğğœğğ§ğ­ğ¥ğ² ğ”ğ¬ğğ (ğ‹ğ‘ğ”) - Removes the least recently accessed item first. - Works well when older data is less likely to be used again. - Example: Browsers use LRU to discard old pages from memory when opening new tabs.",
	"Caching - Eviction - LFU": "ğ‹ğğšğ¬ğ­ ğ…ğ«ğğªğ®ğğ§ğ­ğ¥ğ² ğ”ğ¬ğğ (ğ‹ğ…ğ”) - Evicts the least accessed items over time. - Prioritizes keeping frequently used items in cache. - Example: CDNs use LFU to keep trending videos in cache while removing rarely watched ones.",
	"Caching - Eviction - MRU": "ğŒğ¨ğ¬ğ­ ğ‘ğğœğğ§ğ­ğ¥ğ² ğ”ğ¬ğğ (ğŒğ‘ğ”) - Opposite of LRU â€“ evicts the most recently accessed item first. - Useful when recent data becomes obsolete quickly. - Example: In a music streaming app, the last played song is less likely to be played again, making MRU a better choice.",
	"Caching - Eviction - TTL": "ğ“ğ¢ğ¦ğ ğ­ğ¨ ğ‹ğ¢ğ¯ğ (ğ“ğ“ğ‹) - Items are evicted after a set time limit (expiry time). - Prevents stale data, useful in distributed systems. - Example: DNS records have TTL values, so if an IP address changes, clients donâ€™t hold onto outdated mappings.",
	"Caching - Eviction - FIFO": "ğ…ğ¢ğ«ğ¬ğ­ ğˆğ§, ğ…ğ¢ğ«ğ¬ğ­ ğğ®ğ­ (ğ…ğˆğ…ğ) - Evicts the oldest stored item first, regardless of usage. - Simple to implement but may remove still-relevant data. - Example: Simple queue-based caching systems.",
	"Caching - Eviction - RR": "ğ‘ğšğ§ğğ¨ğ¦ ğ‘ğğ©ğ¥ğšğœğğ¦ğğ§ğ­ (ğ‘ğ‘) - Randomly evicts an item when the cache is full. - Low overhead, but less predictable performance. - Example: Some network routers use RR for managing limited memory, avoiding complex eviction policies.",
	"Caching - Eviction - TT": "ğ“ğ°ğ¨-ğ“ğ¢ğğ«ğğ ğ‚ğšğœğ¡ğ¢ğ§ğ  - Uses a fast in-memory cache (e.g., Redis) & a slower persistent cache (e.g., disk-based). - Optimizes speed & storage by balancing hot and cold data. - Example: A CDN stores frequently accessed content in RAM (L1 cache) while keeping less-accessed content on disk (L2 cache) to balance performance and cost.",

	"Pagination": "SECTION",
	"Pagination - OffsetBased": "This technique uses an offset and a limit parameter to define the starting point and the number of records to return. Example: GET /orders?offset=0&limit=3 ",
	"Pagination - CursorBased": "This technique uses a cursor (a unique identifier) to mark the position in the dataset. Typically, the cursor is an encoded string that points to a specific record. Example: GET /orders?cursor=xxx ",
	"Pagination - PageBased": "This technique specifies the page number and the size of each page. Example: GET /items?page=2&size=3 ",
	"Pagination - KeysetBased": "This technique uses a key to filter the dataset, often the primary key or another indexed column. Example: GET /items?after_id=102&limit=3 ",
	"Pagination - TimeBased": "This technique uses a timestamp or date to paginate through records. Example: GET /items?start_time=xxx&end_time=yyy ",
	"Pagination - Hybrid": "This technique combines multiple pagination techniques to leverage their strengths. Example: Combining cursor and time-based pagination for efficient scrolling through time-ordered records. ",

	"Transactions": "SECTION",
	"Transactions - Principles - Data - ACID": "ACID: Atomicity, Consistency, Isolation, Durability",
	"Transactions - Principles - Data - ACID - Atomicity": "The DB must treat each transaction as all or nothing, if any part fails, the whole transaction must be rolled back as if it never happened.",
	"Transactions - Principles - Data - ACID - Atomicity - Orthogonality": "Atomicity does not behave completely orthogonally with regard to the other ACID properties of transactions. For example, isolation relies on atomicity to roll back the enclosing transaction in the event of an isolation violation such as a deadlock; consistency also relies on atomicity to roll back the enclosing transaction in the event of a consistency violation by an illegal transaction. As a result of this, a failure to detect a violation and roll back the enclosing transaction may cause an isolation or consistency failure.",
	"Transactions - Principles - Data - ACID - Consistency": "A catch-all term that means all the rules defined in the database must be followed when committing a transaction. The end state, at the end of the transaction, must be valid. Rules here can mean data constraints, cascades, triggers, etc. Consistency relies on atomicity, in that if there is a violation, we rely on the systems ability to roll back changes.",
	"Transactions - Principles - Data - ACID - Isolation": "The isolation determines the visibility of changes made by one transaction for another transactions. Ideally, the result of 2 concurrent operations should be the same as if they occurred sequentially.",
	"Transactions - Principles - Data - ACID - Isolation - Transactions": "A transaction is an unit of work that helps to respect ACID principle. This unit of work can only be executed entirely. It means that database will see zero (if transaction fails, operation called rollback) or all operations placed inside transaction (if transaction succeeds, operation called commit).",
	"Transactions - Principles - Data - ACID - Isolation - Transactions - levels": "They're 4 mains transaction's isolation levels: read uncommited, read commited, repeatable read, serializable",
	"Transactions - Principles - Data - ACID - Isolation - Transactions - levels - ReadUncommited": "imagine two transactions, 'A' and 'B'. First, 'A' writes a data into one table without commiting the transaction. After, 'B' reads the uncommited data and work on it. But some error occurs on commiting the 'A' transaction and all changes are rollbacked. In this case, 'B' continues to work on uncommited data by the 'A' transaction. This mode is very fast but can introduce a lot of data consistency problems",
	"Transactions - Principles - Data - ACID - Isolation - Transactions - levels - ReadCommitted": "we still use the same scenario as for read uncommited, but commited data is locked. It means that 'B' can't see uncommited data from the 'A' transaction. 'B' can see it only when 'A' will commit its transaction.",
	"Transactions - Principles - Data - ACID - Isolation - Transactions - levels - RepeatableRead": "this isolation level promotes the same data read, even if the data was changed meanwhile. We continue to work with our 'A' and 'B' transactions. First, 'B' makes a SELECT query and lock selected rows. After, 'A' makes an INSERT query. 'B' executes a new SELECT query with the same conditions as the first one. 'B' will now see the same results as previously (the second SELECT must be made under the same transaction as the first one).",
	"Transactions - Principles - Data - ACID - Isolation - Transactions - levels - Serializable": "this level occurs when our 'B' transaction reads the data and lock whole data's table. It means that another transaction can't modify the data on this table. Unlike read uncommited, this way is the most secure. But in the other hand, it's also the slowest solution.",
	"Transactions - Principles - Data - ACID - Isolation - Reads": "Transaction isolation levels can lead to incoscient data reads. We can distinguish 3 types of these reads: Dirty, Phantom and NonRepeatable",
	"Transactions - Principles - Data - ACID - Isolation - Reads - States - DirtyRead ": "caused by read uncommited level. In this inconsistency, data is different for two or more participating transactions. For example, the first transaction can read the uncommitted data by the second transaction.",
	"Transactions - Principles - Data - ACID - Isolation - Reads - States - PhantomRead": "occurs when two identical queries, executed inside the same transaction, return different set of rows. So, it consists on reading two different set of values, inside the same transaction. But unlike dirty read, all data of phantom read are committed. Yes, it's called phantom because the first and the second SELECT queries contain some phantom data (data absent in the first SELECT results or in the second one)",
	"Transactions - Principles - Data - ACID - Isolation - Reads - States - NonRepeatableRead": "this problem looks almost as a phantom read. But unlike phantom, non-repetable read is applied the same results. Imagine that 'B' reads one row at the first time (for example, a row with id = 30) and 'A' changes one of this row's values (for example, name). After the commit of 'A' transaction, 'B' reads again the same row inside the same transaction. But regarding to the first SELECT, it retrieves the row with the different values. This error can be produced when read committed isolation level is applied to the transactions. It's called non-repeatable because the result of first read of 'B' can't be repeatead in the second read.",
	"Transactions - Principles - Data - ACID - Durability": "Transactions that have committed must survive permanently, even if the system crashes. This is usually assured by writing transactions into a log before acknowledging the commit. The log is on non-volatile storage and can be used to recreate the system state prior to failure (often automatically).",
	"Transactions - Principles - Data - BASE": ".",
	"Transactions - Principles - Data - BASE - ConsistencyModel": "BASE properties are looser than ACID. A BASE datastore values availability and scale, instead of guaranteed consistency. Used by NoSQL stores, including column family, key-value and document stores.",
	"Transactions - Principles - Data - BASE - BasicAvailability": "The database appears to work most of the time.",
	"Transactions - Principles - Data - BASE - SoftState": "Stores do not have to be write-consistent, nor do different replicas have to be mutually consistent all the time.",
	"Transactions - Principles - Data - BASE - EventualConsistency": "Stores exhibit consistency at some later point (e.g., lazily at read time).",
	"Transactions - Principles - Data - NewSQL": "https://levelup.gitconnected.com/newsql-databases-the-best-of-both-worlds-8727411a49ec",
	"Transactions - TransactionalMonitor": "",
	"Transactions - JTA": "Java Transaction API",
	"Transactions - XA": "XA is a two-phase commit protocol that is natively supported by many databases and transaction monitors.",

	"Techniques - Transactions": "https://medium.com/@patrickkoss/interview-so-how-do-you-do-a-transaction-with-nosql-databases-c3d80bc7d314",
	"Techniques - Transactions - Isolation": "https://medium.com/@patrickkoss/interview-so-how-do-you-do-a-transaction-with-nosql-databases-c3d80bc7d314",
	"Techniques - Transactions - Isolation. - States": "Isolation levels defines the degree to which a transaction must be isolated from the data modifications made by any other transaction in the database system. A transaction isolation level are defined by the following phenomena: Dirty Read, Non Repeatable read, Phantom Read",
	"Techniques - Transactions - Isolation. - States. Dirty Read": "A Dirty read is the situation when a transaction reads a data that has not yet been commited.",
	"Techniques - Transactions - Isolation. - States. Non Repeatable read": "Non Repeatable read occurs when a transaction reads same row twice, and get a different value each time. For example, suppose transaction T1 reads a data. Due to concurrency, another transaction T2 updates the same data and commit, Now if transaction T1 rereads the same data, it will retrieve a different value.",
	"Techniques - Transactions - Isolation. - States. Phantom Read": "Phantom Read occurs when two same queries are executed, but the rows retrieved by the two, are different.",
	"Techniques - Transactions - Isolation. - Levels": "The SQL standard defines four isolation levels: Read Uncommitted, Read Committed, Repeatable Read, Serializable",
	"Techniques - Transactions - Isolation. - Levels. Read Uncommitted": "Read Uncommitted is the lowest isolation level. In this level, one transaction may read not yet commited changes made by other transaction, thereby allowing dirty reads. In this level, transactions are not isolated from each other.",
	"Techniques - Transactions - Isolation. - Levels. Read Committed": "This isolation level guarantees that any data read is committed at the moment it is read. Thus it does not allows dirty read. The transaction hold a read or write lock on the current row, and thus prevent other rows from reading, updating or deleting it.",
	"Techniques - Transactions - Isolation. - Levels. Repeatable Read": "This is the most restrictive isolation level. The transaction holds read locks on all rows it references and write locks on all rows it inserts, updates, or deletes. Since other transaction cannot read, update or delete these rows, consequently it avoids non repeatable read.",
	"Techniques - Transactions - Isolation. - Levels. Serializable": "This is the Highest isolation level. A serializable execution is defined to be an execution of the operations of concurrently executing SQL-transactions that produces the same effect as some serial execution of those same SQL-transactions. A serial execution is one in which each SQL-transaction executes to completion before the next SQL-transaction begins.",

	"Indexing": "SECTION",
	"Indexing ": "A special data structure related to a database table and used for storing its important parts and enabling faster data search and retrieval. Indexes are especially efficient for large databases, where they significantly enhance query performance.",
	"Indexing - Unique": "Unique index â€“ doesn't allow duplicates in a table column and hence helps maintain data integrity.",
	"Indexing - Clustered": "Clustered index â€“ defines the physical order of records of a database table and performs data searching based on the key values. A table can have only one clustered index.",
	"Indexing - Non-clustered": "Non-clustered index â€“ keeps the order of the table records that don't match the physical order of the actual data on the disk. It means that the data is stored in one place and a non-clustered index â€“ in another one. A table can have multiple non-clustered indexes.",
	"Indexing - B-Tree": "B-trees, short for balanced trees, are the most common type of database index. A B-tree index is an ordered list of values divided into ranges. By associating a key with a row or range of rows, B-trees provide excellent retrieval performance for a wide range of queries, including exact match and range searches.",
	"Indexing - Bitmap": "In a bitmap index, the database stores a bitmap for each index key. In a conventional B-tree index, one index entry points to a single row. In a bitmap index, each index key stores pointers to multiple rows. Bitmap indexes are primarily designed for data warehousing or environments in which queries reference many columns in an ad hoc fashion.",

	"DataStructures": "SECTION",
	"DataStructures - all": "https://medium.com/@ashishps/how-i-mastered-data-structures-and-algorithms-eb8c5273c56d",

	"ID": "SECTION",
	"ID - UUID": "A UUID (Universally Unique Identifier) is a 128-bit number used to uniquely identify objects or records in computer systems. There are multiple versions of UUIDs.",
	"ID - UUID - unique": "UUIDs are not guaranteed to be unique, instead they are given a certain (typically very low) probability of collision. The probability of generating two UUIDs (especially v4 or v7) that collide is very low, but not zero.",
	"ID - UUIDv1 - Time-based": "A combination of the current timestamp and the MAC address of the machine, unique but may expose hardware information.",
	"ID - UUIDv2 - DCE Security": "Similar to Version 1 but includes POSIX UID/GID information, for applications requiring user or group identification.",
	"ID - UUIDv3 - Name-based, MD5": "Hashes a namespace identifier and a name using the MD5 algorithm, producing consistent UUIDs for the same input data.",
	"ID - UUIDv4 - Random": "Uses random numbers, offering simplicity and a low probability of duplication. e942bbe9-afdc-4c62-a438-4efee77954b3 You can tell itâ€™s UUIDv4 because the digit â€˜4â€™ appears in the 13th position. This is a key identifier for the version of the UUID.",
	"ID - UUIDv5 - Name-based, SHA-1": "Similar to Version 3 but uses the SHA-1 hashing algorithm, providing a more secure hash function for generating UUIDs from names.",
	"ID - UUIDv6 - Ordered Time-based": "A reordering of Version 1 UUIDs to improve database indexing by placing the timestamp in the most significant bits, facilitating chronological ordering. May be suitable for some use cases of database keys needing ordering.",
	"ID - UUIDv7 - Unix Epoch Timestamp": "Encodes a Unix timestamp with millisecond precision in the most significant 48 bits, followed by random data, ensuring uniqueness and time-ordering. 01922e13-43f2-79ef-ab97-ca7a7d021d34 UUIDv7 is a time-based version of UUID, meaning that the identifiers are generated in an increasing order.",
	"ID - UUIDv7 - ordered": "Because the UUIDs are time-based, they are ordered, which leads to better indexing performance compared to the randomness of UUIDv4.",
	"ID - UUIDv8 - Custom": "Reserved for custom implementations, allowing for the inclusion of application-specific data within the UUID structure.",
	"ID - ULID": "Universally Unique Lexicographically Sortable Identifier. ULID is a UUID alternative that is also globally unique, but with the added benefit of being lexicographically sortable.",
	"ID - Auto-IncrementingIDs": ".",
	"ID - SnowflakeID": "Twitter. A distributed ID generation algorithm that generates 64-bit unique IDs using a combination of a timestamp, machine ID, and sequence number.",
	"ID - KSUID": "KSUID (K-Sortable Unique Identifier). KSUIDs are a variation of UUIDs that include a timestamp, making them sortable by creation time. A 27-character string consisting of a timestamp and randomly generated bits, ensuring k-sortability.",
	"ID - NanoID": "NanoID is a small, fast, and secure alternative to UUID, designed to be URL-friendly and customizable in terms of size. A short, random, URL-friendly string with customizable length and alphabet.",
	"ID - RandomHash-BasedID": "Random Hash-Based ID (SHA-256 or MD5 Hashing). Randomly generated strings using hash functions like SHA-256 or MD5 to create unique identifiers. A fixed-length 32- or 64-character string generated by hashing data (like a combination of timestamp and user data).",
	"ID - ObjectID": "ObjectID (MongoDB ObjectID). MongoDBâ€™s ObjectID (BSON binary JSON) is a 12-byte unique identifier that includes a timestamp, machine identifier, process identifier, and a counter.",
	"ID - CUID2": "CUID2 (Collision-Resistant Unique Identifier). Cuid2 is designed to minimize the likelihood of collision in distributed systems, providing a URL-safe, human-readable, and collision-resistant ID.",
	"ID - FlakeID": "Includes a timestamp, machine identifier, and sequence number. If you require unique, time-ordered identifiers for easier sorting and debugging. Example: 304857642123456",
	"ID - Time-basedIDs": "Often a Unix timestamp concatenated with random bits or other unique data. Where chronological order is important, such as logging or event tracking.",
	"ID - SequentialGUIDs": "A GUID optimized for indexing, often beginning with a time-ordered segment. Where GUIDs are necessary, but ordered indexing is needed for better database performance. Example: 6E4F6A80-4F64-11EE-B4FA-0242AC120002",
	"ID - ShortID": "Generates a compact, unique alphanumeric string, often used in URLs. URL shortening or user-friendly identifiers in public URLs. Example: 2K5czP8",
	"ID - ZUID": "ZUID (Zero-width Unique Identifier): Involves zero-width characters (e.g., zero-width spaces) that are invisible but can be parsed for uniqueness. If you need invisible identifiers for tracking or metadata without impacting visual layout. Example: Internally may look like \u200B\u200C\u200D"

}