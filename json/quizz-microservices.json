{
	"Microservices": "SECTION",
	"Microservices - Monolithic": "Build an application with a monolithic architecture. For example: a single Java WAR file. a single directory hierarchy of Rails or NodeJS code",
	"Microservices - Monolithic - Scaling": "",
	"Microservices - Monolithic - Scaling - Dimensions": "In their book “The Art of Scalability,” Martin Abbott and Michael Fisher elaborate on the concept of the “scale cube,”. (X) Each service can then be further scaled by cloning (X-axis), (Y) The microservices pattern maps to the Y-axis of the cube, wherein functional decomposition is used to scale the system (Z) sharding (Z-axis).",
	"Microservices - Monolithic - Scaling - Scale Cube - X - clone services (horizontal duplication)": "X-axis scaling consists of running multiple copies of an application behind a load balancer. If there are N copies then each copy handles 1/N of the load. This is a simple, commonly used approach of scaling an application. One drawback of this approach is that because each copy potentially accesses all of the data, caches require more memory to be effective. Another problem with this approach is that it does not tackle the problems of increasing development and application complexity.",
	"Microservices - Monolithic - Scaling - Scale Cube - y - microservices (functional decomposition)": "Unlike X-axis and Z-axis, which consist of running multiple, identical copies of the application, Y-axis axis scaling splits the application into multiple, different services. Each service is responsible for one or more closely related functions. There are a couple of different ways of decomposing the application into services. One approach is to use verb-based decomposition and define services that implement a single use case such as checkout. The other option is to decompose the application by noun and create services responsible for all operations related to a particular entity such as customer management. An application might use a combination of verb-based and noun-based decomposition.",
	"Microservices - Monolithic - Scaling - Scale Cube - z - sharding databases (data partioning)": "When using Z-axis scaling each server runs an identical copy of the code. In this respect, it’s similar to X-axis scaling. The big difference is that each server is responsible for only a subset of the data. Some component of the system is responsible for routing each request to the appropriate server. One commonly used routing criteria is an attribute of the request such as the primary key of the entity being accessed. Another common routing criteria is the customer type. For example, an application might provide paying customers with a higher SLA than free customers by routing their requests to a different set of servers with more capacity.",
	"Microservices - Microservice": "Define an architecture that structures the application as a set of loosely coupled, collaborating services.",
	"Microservices - Microservice - CAP": "According to CAP theorem, microservices sacrify consistency to improve availabity",
	"Microservices - Microservice - Eventual Consistent": "3 approaches: (1) remove inconsistenct by design (event sourcing + CQRS), (2) address the inconsistency (saga), (3) accept the inconsistency",
	"Microservices - Microservice - Priorities": "(0) Eventual Consistency (1) Decomposition + Storage (2) Service Discovery + Publishing + Commnication Style + Deployment (3) UI + Testing + Configuration + Observability + Security + Reliability +  ",

	"Patterns": "SECTION",
	"Patterns - Tuning": "",
	"Patterns - Tuning - UI Patterns": "Server-side page fragment composition - Client-side UI composition",
	"Patterns - Tuning - UI Patterns - Pattern Server-side page fragment composition": "Each team developers a web application that generates the HTML fragment that implements the region of the page for their service. A UI team is responsible for developing the page templates that build pages by performing server-side aggregation (e.g. server-side include style mechanism) of the service-specific HTML fragments.",
	"Patterns - Tuning - UI Patterns - Pattern Client-side UI composition": "Each team develops a client-side UI component, such an AngularJS directive, that implements the region of the page/screen for their service. A UI team is responsible implementing the page skeletons that build pages/screens by composing multiple, service-specific UI components.",
	"Patterns - Tuning - Observability (Monitoring)": "Observability (logs, traces, metrics, events): Monitoring + Alerting/visualization + Distributed systems tracing infrastructure + Log aggregation/analytics: Log aggregation - Application metrics - Audit logging - Distributed tracing - Exception tracking - Health check API - Log deployments and changes",
	"Patterns - Tuning - Observability (Monitoring) - Patttern Log aggregation": "Use a centralized logging service that aggregates logs from each service instance. The users can search and analyze the logs. They can configure alerts that are triggered when certain messages appear in the logs.",
	"Patterns - Tuning - Observability (Monitoring) - Patttern Application metrics": "Instrument a service to gather statistics about individual operations. Aggregate metrics in centralized metrics service, which provides reporting and alerting. There are two models for aggregating metrics: push - the service pushes metrics to the metrics service pull - the metrics services pulls metrics from the service",
	"Patterns - Tuning - Observability (Monitoring) - Patttern Audit logging": "Record user activity in a database.",
	"Patterns - Tuning - Observability (Monitoring) - Patttern Distributed tracing": "Instrument services with code that: Assigns each external request a unique external request id. Passes the external request id to all services that are involved in handling the request. Includes the external request id in all log messages. Records information (e.g. start time, end time) about the requests and operations performed when handling a external request in a centralized service. This instrumentation might be part of the functionality provided by a Microservice Chassis framework.",
	"Patterns - Tuning - Observability (Monitoring) - Patttern Exception tracking": "Report all exceptions to a centralized exception tracking service that aggregates and tracks exceptions and notifies developers.",
	"Patterns - Tuning - Observability (Monitoring) - Patttern Health check API": "A service has an health check API endpoint (e.g. HTTP /health) that returns the health of the service. The API endpoint handler performs various checks, such as: the status of the connections to the infrastructure services used by the service instance, the status of the host, e.g. disk space, application specific logic A health check client - a monitoring service, service registry or load balancer - periodically invokes the endpoint to check the health of the service instance.",
	"Patterns - Tuning - Observability (Monitoring) - Patttern Log deployments and changes": "Log every deployment and every change to the (production) environment.",
	"Patterns - Tuning - Observability (Monitoring) - Product - Prometheus": "Prometheus is an open-source toolkit for monitoring and alerting based on an embedded times-series database, a query DSL and various mechanics for scraping metrics data off endpoints.",
	"Patterns - Tuning - Testing": "Unit Testing, Integration Testing, Contract Testing, End-to-End Testing",
	"Patterns - Tuning - Testing - End-to-End Testing": "End-to-End (E2E) testing ascertains that the overall system is accurately working as well as the network infrastructure (load balancers, firewall, and more) is correctly configured. E2E tests, however, need to be run at the finest coarse granularity possible to test the functionality of the entire system. In this, QA engineers verify the behavior of the fully-integrated process and make sure that the system collectively meets its business requirements, regardless of the Service Component Architecture in use. With the help of functional testing, developers can determine if an integrated system or app functions as stated in the requirements.",
	"Patterns - Tuning - Testing - Contract Testing": "Contract testing is a sort of a black box that verifies the contract between an external service call and its API provider endpoint. There are two types of contract testing, including: Integration contract testing, Consumer-driven contract testing",
	"Patterns - Tuning - Testing - Contract Testing - Integration contract testing": "In integration contract testing, each component needs to be called independently, and it must meet the contract agreement anticipated by a consuming service. The best way to deal with this is to carry out a test against the double. On a side note, it’s critical to run a separate set of tests periodically to confirm that there are no changes against your test doubles. However, a failure in these tests can slow down the deployment pipeline and disrupt the functionality of an IT infrastructure or distributed system. One best possible way to handle intermittent test failures is by updating your test doubles, and probably the code too so as to bring them back into high coherence and consistency with external services.",
	"Patterns - Tuning - Testing - Contract Testing - Consumer-driven contract testing": "In consumer-driven contract testing, consumers will delineate the way in which they want to consume a service. The consumer contracts can be made in a mutually consented language and schema between the producer and consumer. The service providers will test a service against the replicas of the individual contracts, and then make changes to that particular service without impacting the nature of other services.",
	"Patterns - Tuning - Testing - Integration Testing": "Integration testing takes place in the staging environment to integrate individual services after analyzing the functionality of communication pathways and interactions between them. Unlike monolithic or SOA, microservices architecture depends on the Inter-Process Communication (IPC) mechanism to function appropriately, which is why the interactions between services must be verified. Automated tests need to be written for mapping out the success and error cases through the integration with external services and data stores. Running gateway integration tests will defect interface errors, such as incorrect SSL handling and missing HTTP headers, at the protocol level. And the persistence integration test ensures that each component and protocol client must respond as an external dependency in case of timeouts and partial failures.",
	"Patterns - Tuning - Testing - Unit Testing": "The scope of unit testing can be sociable or solitary concerning a service. The smaller the unit will be under test, the easier it is to determine the behavior of modules and probe the collaborators as well as interactions between objects and their dependencies. Since the cyclomatic complexity of the unit is inferior, Quality Analysis (QA) engineers can evaluate whether or not the units are isolated from their collaborators by using this testing strategy. Both the sociable and solitary unit testing styles are frequently used simultaneously in the same codebase to tackle different testing issues. The motive behind testing the domain layer is to emulate DML statements and certify that all collaborators use the real domain objects in correct sequence. During the unit testing, engineers can verify the logic used to generate map responses or other requests from external remote dependencies. As far as resources and service layer are concerned, they validate that each component correctly interacts with its collaborator, thereby monitoring the request/response cycle in a repeatable and consistent manner.",
	"Patterns - Tuning - Cross cutting": "Microservice chassis - Externalized configuration",
	"Patterns - Tuning - Cross cutting concerns - Patttern Microservice chassis": "Build your microservices using a microservice chassis framework, which handles cross-cutting concerns",
	"Patterns - Tuning - Cross cutting concerns - Patttern Externalized configuration": "Externalize all application configuration including the database credentials and network location. On startup, a service reads the configuration from an external source, e.g. OS environment variables, etc.",
	"Patterns - Tuning - Security. Transport": "TLS/HTTPS",
	"Patterns - Tuning - Security. Input Validations - Message Size": "",
	"Patterns - Tuning - Security. Input Validations - SQL Injection": "",
	"Patterns - Tuning - Security. Input Validations - JSON Threat Protection": "",
	"Patterns - Tuning - Security. Input Validations - XML Threat Protection": "",
	"Patterns - Tuning - Security. Authentication - JWT": "The API Gateway authenticates the request and passes an access token.",
	"Patterns - Tuning - Security. Authentication - JWT - JSON": "You can think of JWT as a piece of JSON data that you can verify to confirm that the data comes from someone you trust.",
	"Patterns - Tuning - Security. Authentication - JWT - cookies": "In practice, in most web authentication cases, JWT data is stored in session cookies, meaning you now have two layers of signatures: one on the cookie itself and one on the JWT.",
	"Patterns - Tuning - Security. Authentication - OpenID Connect": "",
	"Patterns - Tuning - Security. Authentication - OAuth2": "",
	"Patterns - Tuning - Security. Authentication - SAML": "",			
	"Patterns - Tuning - Reliability": "Circuit Breaker",
	"Patterns - Tuning - Reliability - Pattern Circuit Breaker": "A service client should invoke a remote service via a proxy that functions in a similar fashion to an electrical circuit breaker. When the number of consecutive failures crosses a threshold, the circuit breaker trips, and for the duration of a timeout period all attempts to invoke the remote service will fail immediately. After the timeout expires the circuit breaker allows a limited number of test requests to pass through. If those requests succeed the circuit breaker resumes normal operation. Otherwise, if there is a failure the timeout period begins again.",
	"Patterns - Tuning - Reliability - Pattern Circuit Breaker - Product": "Hystrix",
	"Patterns - Implementation - Publishing": "",
	"Patterns - Implementation - Publishing - API Gateway": "API Gateway - Backend for front-end. Implement an API gateway that is the single entry point for all clients. The API gateway handles requests in one of two ways. Some requests are simply proxied/routed to the appropriate service. It handles other requests by fanning out to multiple services.",
	"Patterns - Implementation - Publishing - API Gateway vs Load Balancer": "API Gateway is a traffic manager at Layer 7 of OSI Model. Load Balancer is a network distributor at Layer 4 or 7 of OSI Model.",
	"Patterns - Implementation - Publishing - Service Mess": "A service mesh is a configurable infrastructure layer for a microservices application. It makes communication between service instances flexible, reliable, and fast. The mesh provides service discovery, load balancing, encryption, authentication and authorization, support for the circuit breaker pattern, and other capabilities.",
	"Patterns - Implementation - Publishing - Service Mess - Product - Istio": "",
	"Patterns - Implementation - Publishing - Service Mess vs API Gateway": "A service mesh's primary purpose is to manage internal service-to-service communication, while an API Gateway is primarily meant for external client-to-service communication. The main purpose of an API gateway is to accept traffic from outside your network and distribute it internally. The main purpose of a service mesh is to route and manage traffic within your network. A service mesh can work with an API gateway to efficiently accept external traffic then effectively route that traffic once it's in your network. The combination of these technologies can be a powerful way to ensure application uptime and resiliency while ensuring your applications are easily consumable. In a deployment with an API gateway and a service mesh, incoming traffic from outside the cluster would first be routed through the API gateway, then into the mesh. it seems highly likely that service mesh and API gateway functionality will merge. In the next few years, we believe that standalone API gateways will be used less and less as much of their functionality will be absorbed by service mesh.",
	"Patterns - Implementation - Publishing - Backend for front-end": "A variation of this pattern is the Backend for Front-End pattern. It defines a separate API gateway for each kind of client.",
	"Patterns - Implementation - Service discovery": "Client-side discovery - Server-side discovery - Service registry - Self registration - 3rd party registration",
	"Patterns - Implementation - Service discovery - Pattern Client-side discovery": "When making a request to a service, the client obtains the location of a service instance by querying a Service Registry, which knows the locations of all service instances.",
	"Patterns - Implementation - Service discovery - Pattern Server-side discovery": "When making a request to a service, the client makes a request via a router (a.k.a load balancer) that runs at a well known location. The router queries a service registry, which might be built into the router, and forwards the request to an available service instance.",
	"Patterns - Implementation - Service discovery - Pattern Service registry": "Implement a service registry, which is a database of services, their instances and their locations. Service instances are registered with the service registry on startup and deregistered on shutdown. Client of the service and/or routers query the service registry to find the available instances of a service. A service registry might invoke a service instance’s health check API to verify that it is able to handle requests",
	"Patterns - Implementation - Service discovery - Pattern Self registration": "A service instance is responsible for registering itself with the service registry. On startup the service instance registers itself (host and IP address) with the service registry and makes itself available for discovery. The client must typically periodically renew its registration so that the registry knows it is still alive. On shutdown, the service instance unregisters itself from the service registry.",
	"Patterns - Implementation - Service discovery - Pattern 3rd party registration": "A 3rd party registrar is responsible for registering and unregistering a service instance with the service registry. When the service instance starts up, the registrar registers the service instance with the service registry. When the service instance shuts downs, the registrar unregisters the service instance from the service registry.",
	"Patterns - Implementation - Service discovery - Product": "Eureka",
	"Patterns - Implementation - Communication Style": "RPC - Messaging - Domain Specific Protocol",
	"Patterns - Implementation - Communication Style - Pattern RPC": "Use RPI for inter-service communication. The client uses a request/reply-based protocol to make requests to a service.",
	"Patterns - Implementation - Communication Style - Pattern Messaging": "Use asynchronous messaging for inter-service communication. Services communicating by exchanging messages over messaging channels.",
	"Patterns - Implementation - Communication Style - Pattern Domain Specific Protocol": "Use a domain-specific protocol for inter-service communication.",
	"Patterns - Implementation - Deployment": "Multiple services per host - service per host - service per VM - service per container - serverless - specific serviecs platform",
	"Patterns - Implementation - Deployment - Patttern Multiple services per host": "Run multiple instances of different services on a host (Physical or Virtual machine). There are various ways of deploying a service instance on a shared host including: Deploy each service instance as a JVM process. For example, a Tomcat or Jetty instances per service instance. Deploy multiple service instances in the same JVM. For example, as web applications or OSGI bundles.",
	"Patterns - Implementation - Deployment - Patttern service per host": "Deploy each single service instance on its own host",
	"Patterns - Implementation - Deployment - Patttern service per VM": "Package the service as a virtual machine image and deploy each service instance as a separate VM",
	"Patterns - Implementation - Deployment - Patttern service per container": "Package the service as a (Docker) container image and deploy each service instance as a container",
	"Patterns - Implementation - Deployment - Patttern serverless": "Use a deployment infrastructure that hides any concept of servers (i.e. reserved or preallocated resources)- physical or virtual hosts, or containers. The infrastructure takes your service’s code and runs it. You are charged for each request based on the resources consumed. To deploy your service using this approach, you package the code (e.g. as a ZIP file), upload it to the deployment infrastructure and describe the desired performance characteristics. The deployment infrastructure is a utility operated by a public cloud provider. It typically uses either containers or virtual machines to isolate the services. However, these details are hidden from you. Neither you nor anyone else in your organization is responsible for managing any low-level infrastructure such as operating systems, virtual machines, etc.",
	"Patterns - Implementation - Deployment - Patttern specific serviecs platform": "Use a deployment platform, which is automated infrastructure for application deployment. It provides a service abstraction, which is a named, set of highly available (e.g. load balanced) service instances.",
	"Patterns - Data - Decomposition": "by Business Capability - by Subdomain",
	"Patterns - Data - Decomposition - by Capability": "Define services corresponding to business capabilities. A business capability is a concept from business architecture modeling. It is something that a business does in order to generate value. A business capability often corresponds to a business object, e.g. Order Management is responsible for orders Customer Management is responsible for customers Business capabilities are often organized into a multi-level hierarchy. For example, an enterprise application might have top-level categories such as Product/Service development, Product/Service delivery, Demand generation, etc.",
	"Patterns - Data - Decomposition - by Subdomain": "Define services corresponding to Domain-Driven Design (DDD) subdomains. DDD refers to the application’s problem space - the business - as the domain. A domain is consists of multiple subdomains. Each subdomain corresponds to a different part of the business. Subdomains can be classified as follows: Core - key differentiator for the business and the most valuable part of the application Supporting - related to what the business does but not a differentiator. These can be implemented in-house or outsourced. Generic - not specific to the business and are ideally implemented using off the shelf software",
	"Patterns - Data - Decomposition - by maturity": "",
	"Patterns - Data - Decomposition - by data-access": "decomposing by data-access pattern (read versus write)",
	"Patterns - Data - Decomposition - by data source": "decomposition by data source (rather than partitioning a data source per microservice, create a microservice per data source)",
	"Patterns - Data - Decomposition - by functionality": "aggregation for a derived functionality (create an orchestrating service for a few other services)",
	"Patterns - Data - Decomposition - by client": "aggregation for client convenience (such as the backend for frontend pattern)",
	"Patterns - Data - Decomposition - by client - BFF": "At its core, Backend for Frontend is a architecture pattern that provides a dedicated backend layer for each frontend interface. Each frontend (e.g., mobile app, web app, smart device, etc.) may have different performance, data, and interaction needs. Instead of relying on a single monolithic or generalized API, a BFF tailors the backend to the specific needs of a given frontend.",
	"Patterns - Data - Decomposition - by client - BFF Layer": "BFF Layer: The BFF consolidates data from multiple microservices, performs any transformations or optimizations, and responds with a tailored response.",
	"Patterns - Data - Decomposition - by performance": "aggregation to aid system performance",
	"Patterns - Data - Storage": "Main challenge is address the eventual consistency issue: Database per Service - Shared database - Saga - API Composition - CQRS - Event sourcing - Application events",
	"Patterns - Data - Storage - Patttern - Shared database": "Use a (single) database that is shared by multiple services. Each service freely accesses data owned by other services using local ACID transactions.",
	"Patterns - Data - Storage - Patttern - Database per Service": "Keep each microservice’s persistent data private to that service and accessible only via its API. The following diagram shows the structure of this pattern. The service’s database is effectively part of the implementation of that service. It cannot be accessed directly by other services. There are a few different ways to keep a service’s persistent data private. You do not need to provision a database server for each service. For example, if you are using a relational database then the options are: Private-tables-per-service – each service owns a set of tables that must only be accessed by that service Schema-per-service – each service has a database schema that’s private to that service Database-server-per-service – each service has it’s own database server. Private-tables-per-service and schema-per-service have the lowest overhead. Using a schema per service is appealing since it makes ownership clearer. Some high throughput services might need their own database server. It is a good idea to create barriers that enforce this modularity. You could, for example, assign a different database user id to each service and use a database access control mechanism such as grants. Without some kind of barrier to enforce encapsulation, developers will always be tempted to bypass a service’s API and access it’s data directly.",
	"Patterns - Data - Storage - Patttern - 2PC - Not an option": "One attempt to solve this problem in an automated and hassle-free manner is the XA protocol implementing the two-phase commit (2PC) pattern. But in modern high-scale applications (especially in a cloud environment), 2PC doesn’t seem to perform so well. To eliminate the disadvantages of 2PC, we have to trade ACID for BASE and cover consistency concerns ourselves in different ways depending on the requirements.",
	"Patterns - Data - Storage - Patttern - Saga": "Implement each business transaction that spans multiple services as a saga. A saga is a sequence of local transactions. Each local transaction updates the database and publishes a message or event to trigger the next local transaction in the saga. If a local transaction fails because it violates a business rule then the saga executes a series of compensating transactions that undo the changes that were made by the preceding local transactions. There are two ways of coordination sagas: Choreography - each local transaction publishes domain events that trigger local transactions in other services Orchestration - an orchestrator (object) tells the participants what local transactions to execute. Saga provides ACD but misses I (isolation). Products Tram, AXON framework",
	"Patterns - Data - Storage - Patttern - CQRS": "Split the application into two parts: the command-side and the query-side. The command-side handles create, update, and delete requests and emits events when data changes. The query-side handles queries by executing them against one or more materialized views that are kept up to date by subscribing to the stream of events emitted when data changes.",
	"Patterns - Data - Storage - Patttern - Event sourcing": "A good solution to this problem is to use event sourcing. Event sourcing persists the state of a business entity such an Order or a Customer as a sequence of state-changing events. Whenever the state of a business entity changes, a new event is appended to the list of events. Since saving an event is a single operation, it is inherently atomic. The application reconstructs an entity’s current state by replaying the events. Applications persist events in an event store, which is a database of events. The store has an API for adding and retrieving an entity’s events. The event store also behaves like a message broker. It provides an API that enables services to subscribe to events. When a service saves an event in the event store, it is delivered to all interested subscribers. Some entities, such as a Customer, can have a large number of events. In order to optimize loading, an application can periodically save a snapshot of an entity’s current state. To reconstruct the current state, the application finds the most recent snapshot and the events that have occurred since that snapshot. As a result, there are fewer events to replay.",
	"Patterns - Data - Decomposition and Storage - Persisting state (modularization) vs persisting events (aggregates = materialized views)": "by Capability has the problem of 2PC because dependencies (violates encapsulation). We can use Saga but is not ACID but ACD (no isolation). Therefore use DDD aggregates instead modularization. Rules: (1) Refer entitites by primary key. (2) One aggregate to comand per atomic transaction. (3) How to maintain consistency between aggregates?? Events sourcing solves this by persisting events instead state. But has challenge of maintain consistency between aggregates",

	"Protocols - HTTP": "SECTION",

	"Protocols - REST": "SECTION",
	"Protocols - REST - Requirements - Richardson Maturity Model": "",
	"Protocols - REST - Requirements - Richardson Maturity Model - Level0": "Level 0: Swamp of POX. Level 0 uses its implementing protocol (normally HTTP, but it doesn't have to be) like a transport protocol.",
	"Protocols - REST - Requirements - Richardson Maturity Model - Level1": "Level 1: Resources. When your API can distinguish between different resources, it might be level 1. This level uses multiple URIs, where every URI is the entry point to a specific resource.",
	"Protocols - REST - Requirements - Richardson Maturity Model - Level2": "Level 2: HTTP verbs. This level indicates that your API should use the protocol properties in order to deal with scalability and failures. Don't use a single POST method for all, but make use of GET when you are requesting resources, and use the DELETE method when you want to delete a resources. Also, use the response codes of your application protocol. Don't use 200 (OK) code when something went wrong for instance. ",
	"Protocols - REST - Requirements - Richardson Maturity Model - Level3": "Level 3: Hypermedia controls Level 3, the highest level, uses HATEOAS to deal with discovering the possibilities of your API towards the clients.",
	"Protocols - REST - Requirements - REST Constraints": "",
	"Protocols - REST - Requirements - REST Constraints (6 from thesis)": "Uniform Interface, Stateless, Cacheable, Client-Server, Layered System, Code on Demand (optional)",
	"Protocols - REST - Requirements - REST Constraint. 1. Uniform Interface": "*(1) Resource-Based (Individual resources are identified in requests using URIs as resource identifiers), (2) Manipulation of Resources Through Representations (When a client holds a representation of a resource, including any metadata attached, it has enough information to modify or delete the resource on the server, provided i has permission to do so). (3) Self-descriptive Messages (Each message includes enough information to describe how to process the message). (4) Hypermedia as the Engine of Application State (HATEOAS) (Clients deliver state via body contents, query-string parameters, request headers and the requested URI (the resource name). Services deliver state to clients via body content, response codes, and response headers. This is technically referred-to as hypermedia (or hyperlinks within hypertext).",
	"Protocols - REST - Requirements - REST Constraint. 2. Stateless": "As REST is an acronym for REpresentational State Transfer, statelessness is key. Essentially, what this means is that the necessary state to handle the request is contained within the request itself, whether as part of the URI, query-string parameters, body, or headers. The URI uniquely identifies the resource and the body contains the state (or state change) of that resource. Then after the server does it's processing, the appropriate state, or the piece(s) of state that matter, are communicated back to the client via headers, status and response body.",
	"Protocols - REST - Requirements - REST Constraint. 3. Cacheable": "As on the World Wide Web, clients can cache responses. Responses must therefore, implicitly or explicitly, define themselves as cacheable, or not, to prevent clients reusing stale or inappropriate data in response to further requests. Well-managed caching partially or completely eliminates some client–server interactions, further improving scalability and performance.",
	"Protocols - REST - Requirements - REST Constraint. 4. Client-Server": "The uniform interface separates clients from servers. This separation of concerns means that, for example, clients are not concerned with data storage, which remains internal to each server, so that the portability of client code is improved. Servers are not concerned with the user interface or user state, so that servers can be simpler and more scalable. Servers and clients may also be replaced and developed independently, as long as the interface is not altered.",
	"Protocols - REST - Requirements - REST Constraint. 5. Layered System": "A client cannot ordinarily tell whether it is connected directly to the end server, or to an intermediary along the way. Intermediary servers may improve system scalability by enabling load-balancing and by providing shared caches. Layers may also enforce security policies.",
	"Protocols - REST - Requirements - REST Constraint. 6. Code on Demand (optional)": "Servers are able to temporarily extend or customize the functionality of a client by transferring logic to it that it can execute. Examples of this may include compiled components such as Java applets and client-side scripts such as JavaScript. Complying with these constraints, and thus conforming to the REST architectural style, will enable any kind of distributed hypermedia system to have desirable emergent properties, such as performance, scalability, simplicity, modifiability, visibility, portability and reliability. NOTE: The only optional constraint of REST architecture is code on demand. If a service violates any other constraint, it cannot strictly be referred to as RESTful.",
	"Protocols - REST - DesigningRESTAPi - Steps": ".",
	"Protocols - REST - DesigningRESTAPi - Steps - 1-ObjectModel": "(1) Identify Object Model. The very first step in designing a REST API based application is – identifying the objects which will be presented as resources.",
	"Protocols - REST - DesigningRESTAPi - Steps - 2-ResourceURIs": "(2) Now when object model is ready, it’s time to decide the resource URIs. At this step, while designing the resource URIs – focus on the relationship between resources and its sub-resources. These resource URIs are endpoints for RESTful services. These URIs do not use any verb or operation. It’s very important to not include any verb in URIs. URIs should all be nouns only.",
	"Protocols - REST - DesigningRESTAPi - Steps - 3-Representations": "(3) Determine Representations Now when resource URIs have been decided, let’s work on their representations. Mostly representations are defined in either XML or JSON format.",
	"Protocols - REST - DesigningRESTAPi - Steps - 4-HTTPMethods": "(4) Assign HTTP Methods So our resource URIs and their representation are fixed now. Let’s decide the possible operations in application and map these operations on resource URIs. A user of network application can perform browse, create, update or delete operations. So let’s map them.",
	"Protocols - REST - DesigningRESTAPi - Steps - 5-Other": "(5) You need to work on other aspects of the application as well: Logging, Security, Discovery etc.",
	"Protocols - REST - Methods - Are REST and HTTP the same thing?": "There is nothing in the REST constraints that makes the usage of HTTP as a transfer protocol mandatory. It's perfectly possible to use other transfer protocols like SNMP, SMTP and others to use, and your API could still very well be a RESTful API In practice, most - if not all - RESTful APIs currently use HTTP as a transport layer, since the infrastructure, servers and client libraries for HTTP are widely available already",
	"Protocols - REST - Methods - idempotency and safety contract": "It is a contract defined by the HTTP standard that developers must adhere to when implementing RESTful APIs over HTTP. An operation doesn’t automatically become idempotent or safe just because it is invoked using the GET method, if it isn’t implemented in an idempotent manner",
	"Protocols - REST - Methods - safe methods": "Some idempotent operations have an additional, special property: they do not modify the state on the server side at all. Simply put, these methods are read-only and have absolutely zero side-effects. These types of operations are given a special name: safe or nullipotent methods. Safe HTTP method are GET and HEAD, which doesn't change the resource representation on the Server, but all other HTTP methods e.g. POST, PUT, or DELETE are non-safe.",
	"Protocols - REST - Methods - Idempotent methods": "In the context of REST APIs, when making multiple identical requests has the same effect as making a single request – then that REST API is called idempotent. If you follow REST principles in designing API, you will have automatically idempotent REST APIs for GET, PUT, DELETE, HEAD, OPTIONS and TRACE HTTP methods. Only POST APIs will not be idempotent. Idempotency in REST does not mean that consecutive calls to the same method and resource must return the same response, but rather that consecutive calls to the same method and resource MUST have the same intended effect on the server.",
	"Protocols - REST - Methods - HTTP GET": "Use GET requests to retrieve resource representation/information only – and not to modify it in any way. As GET requests do not change the state of the resource, these are said to be safe methods. Additionally, GET APIs should be idempotent. Responses if item: 200 (OK), single user. 404 (Not Found), if ID not found or invalid. Responses if collection: 200 (OK), list of users. Use pagination, sorting and filtering to navigate big lists.",
	"Protocols - REST - Methods - HTTP POST": "POST methods are used to create a new resource into the collection of resources. Responses to this method are not cacheable. POST is neither safe nor idempotent and invoking two identical POST requests will result in two different resources containing the same information (except resource ids). Responses if item: Avoid using POST on single resource. Responses if collection: 201 (Created), ‘Location’ header with link to /users/{id} containing new ID.",
	"Protocols - REST - Methods - HTTP PUT": "Use PUT APIs primarily to update existing resource (if the resource does not exist then API may decide to create a new resource or not). If the request passes through a cache and the Request-URI identifies one or more currently cached entities, those entries SHOULD be treated as stale. Responses to this method are not cacheable. Responses if item: 200 (OK) or 204 (No Content). Use 404 (Not Found), if ID not found or invalid.. Responses if collection: 404 (Not Found), unless you want to update every resource in the entire collection of resource.",
	"Protocols - REST - Methods - HTTP DELETE": "As the name applies, DELETE APIs are used to delete resources (identified by the Request-URI). DELETE operations are idempotent. If you DELETE a resource, it’s removed from the collection of resource. Repeatedly calling DELETE API on that resource will not change the outcome – however calling DELETE on a resource a second time will return a 404 (NOT FOUND) since it was already removed. Some may argue that it makes DELETE method non-idempotent. It’s a matter of discussion and personal opinion. If the request passes through a cache and the Request-URI identifies one or more currently cached entities, those entries SHOULD be treated as stale. Responses to this method are not cacheable. Responses if item: 200 (OK). 404 (Not Found), if ID not found or invalid. Responses if collection: 404 (Not Found), unless you want to delete the whole collection — use with caution.",
	"Protocols - REST - Methods - HTTP PATCH": "HTTP PATCH requests are to make partial update on a resource. If you see PUT requests also modify a resource entity so to make more clear – PATCH method is the correct choice for partially updating an existing resource and PUT should only be used if you’re replacing a resource in its entirety. Support for PATCH in browsers, servers, and web application frameworks is not universal. PATCH method is not a replacement for the POST or PUT methods. It applies a delta (diff) rather than replacing the entire resource. Responses if item: 200 (OK) or 204 (No Content). Use 404 (Not Found), if ID not found or invalid. Responses if collection: 404 (Not Found), unless you want to modify the collection itself.",
	"Protocols - REST - Methods - HTTP OPTIONS": "This method allows the client of the REST API to determine, which HTTP method ( GET, HEAD, POST, PUT, DELETE ) can be used for a resource identified by requested URI, without initiating a resource request by using any particular HTTP method. Response to this method are not cacheable.",
	"Protocols - REST - Methods - HTTP HEAD": "Simply put, HEAD returns all of the HTTP headers, just like GET, but provides no body content. All of the same rules regarding content caching can be applied, regarding headers in the request/response.",
	"Protocols - REST - Methods - HTTP POST vs HTTP PUT vs HTTP PATCH": "PUT is for creating or conmpletely updating a single resource when you know the URL (e.g. create update object). It is idempotent. POST is to create when you do not know the URL (e.g.adding item to a collection). No idempotent, PATCH is to update part of a resource when you know the URL. Idempotent",
	"Protocols - REST - Features": "The basic purpose of HTTP caching is to provide a mechanism for applications to scale better and perform faster.",
	"Protocols - REST - Features ": "HTTP caching involves the client, the proxy, and the server. In this post, we will discuss mainly the proxy, which sits between the client and server. Typically, reverse proxies are deployed close to the server, and forward proxies close to the client.",
	"Protocols - REST - Features - Caching - proxy": "A typical proxy caches idempotent requests. HTTP caching is applicable by default only to idempotent requests, only idempotent and nullipotent requests yield the same result when run multiple times. In the HTTP world, this fact means that GET requests can be cached but POST requests cannot.",
	"Protocols - REST - Features - Caching - idempotent calls": "A typical proxy caches idempotent requests. The proxy gets the request, examines it for cache headers, and sends it to the server. Then the proxy examines the response and, if it is cacheable, caches it with the URL as the key (along with some headers in certain cases) and the response as the value.  This scheme works well with GET requests, because for the same URL repeated invocation does not change the response. Intermediaries can make use of this idempotency to safely cache GET requests. But this is not the case with an idempotent POST request. The URL (and headers) cannot be used as the key because the response could be different – the same URL, but with a different body.",
	"Protocols - REST - Features - Caching - no idempotent calls (POST)": "Responses to POST method are not cacheable, UNLESS the response includes appropriate Cache-Control or Expires header fields.",
	"Protocols - REST - Features - Caching - headers": "HTTP response headers: Expires, Cache-Control, ETag, Last-Modified",
	"Protocols - REST - Features - Compression": "HTTP response headers: Accept-Encoding, Content-Encoding",
	"Protocols - REST - Features - Content Negotiation": "HTTP response headers: Content-Type, Accept",
	"Protocols - REST - Features - Versioning": "(1) Using URI: /api/v1/customer/{id}, (2) Using Custom Request Header: Accept-version: v1, (3) Using Accept header: Accept: application/vnd.example.v1+json",
	"Protocols - REST - Features - Security - Authentication": "",
	"Protocols - REST - Features - Security - Authentication - HTTP Basic Authentication": "",
	"Protocols - REST - Features - Security - Authentication - HTTP Digest Authentication": "",
	"Protocols - REST - Features - Security - Authentication - Token Based Authentication": "",
	"Protocols - REST - Features - Security - Authorization": "",
	"Protocols - REST - Features - Security - Input Validation": "",
	"Protocols - REST - Features - Security - Encryption": "",

	"Protocols - gRPC": "SECTION",
	"Protocols - gRPC - Features": "",
	"Protocols - gRPC - Features - HTTP/2": "gRPC leverages the HTTP/2 protocol under the covers.",
	"Protocols - HTTP - 2": "HTTP/2 began as the SPDY protocol, developed primarily at Google",
	"Protocols - HTTP - 2 - Goal": "Reducing server latency",
	"Protocols - HTTP - 2 - Features - Binary": "binary framing layer. As opposed to HTTP/1.1, which keeps all requests and responses in plain text format, HTTP/2 uses the binary framing layer to encapsulate all messages in binary format, while still maintaining HTTP semantics, such as verbs, methods, and headers.",
	"Protocols - HTTP - 2 - Features - Headers - compression": "Small files load more quickly than large ones. To speed up web performance, both HTTP/1.1 and HTTP/2 compress HTTP messages to make them smaller. However, HTTP/2 uses a more advanced compression method called HPACK that eliminates redundant information in HTTP header packets. This eliminates a few bytes from every HTTP packet. Given the volume of HTTP packets involved in loading even a single webpage, those bytes add up quickly, resulting in faster loading.",
	"Protocols - HTTP - 2 - Features - Prioritization": "Stream prioritization not only solves the possible issue of requests competing for the same resource, but also allows developers to customize the relative weight of requests to better optimize application performance.",
	"Protocols - HTTP - 2 - Features - Multiplexing": "HTTP/1.1 loads resources one after the other, so if one resource cannot be loaded, it blocks all the other resources behind it. In contrast, HTTP/2 is able to use a single TCP connection to send multiple streams of data at once so that no one resource blocks any other resource. HTTP/2 does this by splitting data into binary-code messages and numbering these messages so that the client knows which stream each binary message belongs to.",
	"Protocols - HTTP - 2 - Features - Push": "Server push: Typically, a server only serves content to a client device if the client asks for it. However, this approach is not always practical for modern webpages, which often involve several dozen separate resources that the client must request. HTTP/2 solves this problem by allowing a server to 'push' content to a client before the client asks for it. The server also sends a message letting the client know what pushed content to expect – like if Bob had sent Alice a Table of Contents of his novel before sending the whole thing.",
	"Protocols - HTTP - 3 - Transport": "Both HTTP/1.1 and HTTP/2 use TCP as their transport, whereas HTTP/3 is based on Google’s QUIC – a transport layer network protocol that implements user space congestion control over UDP (User Datagram Protocol).",

	"Formats - Protobuff": "SECTION",
	"Formats - Protobuff - features - binary": "Protobuf is binary-based",
	"Formats - Protobuff - features - contracts": "Everyone uses the same proto file to generate packages to serialize and deserialize.",
	"Formats - Protobuff - features - fast": "faster to transport, a lot faster than JSON during serialization and deserialization.",

	"Formats - JSON": "SECTION",

	"Formats - XML": "SECTION"


}