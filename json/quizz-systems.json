{

	"Apps": "SECTION",
	"Apps - ByState": "Whether something is stateful or stateless depends on how long the state of interaction with it is being recorded and how that information needs to be stored.",
	"Apps - ByState - Stateful": "A stateful application retains state or context about its interactions with users, systems, or components.",
	"Apps - ByState - Stateful - Features - state": "Stateful applications store information about the interaction, often in a database or in distributed memory.",
	"Apps - ByState - Stateful - Features - session": "With stateful applications, each request depends on data or context from previous interactions and transactions.",
	"Apps - ByState - Stateful - Features - persisted": "The state is persisted on a durable storage solution, so that the application survives a restart. Stateful applications require persistent storage (like databases and distributed file systems). Stateful apps must rely on an underlying storage solution, and they need a scheme for synchronizing data between instances.",
	"Apps - ByState - Stateful - Features - resources": "Because stateful applications are more storage dependent, they may require more memory and processing power to handle and maintain session information.",
	"Apps - ByState - Stateful - Features - scalability": "Stateful applications have tightly coupled instances making it more difficult to scale. They may require more specific instances or pods in Kubernetes to manage state, load balance, and manage sessions.",
	"Apps - ByState - Stateful - Features - fault": "In stateful applications, the loss of a server can result in the loss of session data unless additional measures, such as session replication or clustering, are in place.",
	"Apps - ByState - Stateful - Features - idempotency": "Stateless requests are designed to be idempotent, meaning repeated requests have the same effect.",
	"Apps - ByState - Stateless": "A stateless application or process does not retain information about the user's previous interactions.",
	"Apps - ByState - Stateless - Features - state": "Stateless applications don’t store information about an interaction, so a transaction will need to start over.",
	"Apps - ByState - Stateless - Features - session": "Stateless applications have more independent sessions since each request is treated as new, but that means that the application must have all the information necessary to process the request.",
	"Apps - ByState - Stateless - Features - persisted": ".",
	"Apps - ByState - Stateless - Features - resources": "Stateless applications often have lower resource utilization because there is no need to store and manage session data.",
	"Apps - ByState - Stateless - Features - scalability": "Stateless applications are generally more scalable, as each request is independent and can be handled by any available server using load balancing.",
	"Apps - ByState - Stateless - Features - fault": "Stateless applications can be more fault-tolerant, as the loss of a server doesn't impact user sessions",
	"Apps - ByState - Stateless - Features - idempotency": "Stateless requests are designed to be idempotent, meaning repeated requests have the same effect.",
	"Apps - ByState - Stateless - Examples - RESTAPI": "REST application programming interface (APIs) transfer a representation of the state of a resource to the requester or endpoint. Each API request is separate and the server does not store information about the previous request.",
	"Apps - ByState - Stateless - Examples - Microservices": "Microservices allow each core function within an application to exist independently. Because of that, microservices are well suited to both stateless and stateful applications.",
	"Apps - ByState - Stateless - Examples - Serverless": "Serverless architectures: Serverless architectures are designed to respond to events in isolation and do not retain context from previous actions and therefore do not need to maintain state. Serverless architectures are ideal for asynchronous, stateless apps that can be started instantaneously.",

	"Systems - Distributed": "SECTION",
	"Systems - Distributed - Principles - Consistency": "In distributed systems, consistency models define how updates are seen across nodes. Strong consistency and eventual consistency 𝗿𝗲𝗽𝗿𝗲𝘀𝗲𝗻𝘁 𝗯𝗼𝘁𝗵 𝗲𝗻𝗱𝘀 𝗼𝗳 𝘁𝗵𝗲 𝗰𝗼𝗻𝘀𝗶𝘀𝘁𝗲𝗻𝗰𝘆 𝘀𝗽𝗲𝗰𝘁𝗿𝘂𝗺 (sequential and causal consistency in between).",
	"Systems - Distributed - Principles - Consistency - Strong": "↳ Every read sees the latest write ↳ Higher latency, lower availability, higher integrity ↳ Ideal for real-time correctness",
	"Systems - Distributed - Principles - Consistency - Sequential": ".",
	"Systems - Distributed - Principles - Consistency - Causal": ".",
	"Systems - Distributed - Principles - Consistency - Weak": "It is a consistency model used in distributed computing where subsequent accesses might not always be returning the updated value. There might be inconsistent responses.",
	"Systems - Distributed - Principles - Consistency - Eventual": "↳ Reads may return stale data temporarily ↳ Lower latency, higher availability ↳ Great for scale-first systems .",
	"Systems - Distributed - Principles - HA - Scalability": "",
	"Systems - Distributed - Principles - HA - Scalability - Dimensions": "In their book “The Art of Scalability,” Martin Abbott and Michael Fisher elaborate on the concept of the “scale cube,”. (X) Each service can then be further scaled by cloning (X-axis), (Y) The microservices pattern maps to the Y-axis of the cube, wherein functional decomposition is used to scale the system (Z) sharding (Z-axis).",
	"Systems - Distributed - Principles - HA - Scalability - ScaleCube - X - clone services (horizontal duplication)": "X-axis scaling consists of running multiple copies of an application behind a load balancer. If there are N copies then each copy handles 1/N of the load. This is a simple, commonly used approach of scaling an application. One drawback of this approach is that because each copy potentially accesses all of the data, caches require more memory to be effective. Another problem with this approach is that it does not tackle the problems of increasing development and application complexity.",
	"Systems - Distributed - Principles - HA - Scalability - ScaleCube - y - microservices (functional decomposition)": "Unlike X-axis and Z-axis, which consist of running multiple, identical copies of the application, Y-axis axis scaling splits the application into multiple, different services. Each service is responsible for one or more closely related functions. There are a couple of different ways of decomposing the application into services. One approach is to use verb-based decomposition and define services that implement a single use case such as checkout. The other option is to decompose the application by noun and create services responsible for all operations related to a particular entity such as customer management. An application might use a combination of verb-based and noun-based decomposition.",
	"Systems - Distributed - Principles - HA - Scalability - ScaleCube - z - sharding databases (data partioning)": "When using Z-axis scaling each server runs an identical copy of the code. In this respect, it’s similar to X-axis scaling. The big difference is that each server is responsible for only a subset of the data. Some component of the system is responsible for routing each request to the appropriate server. One commonly used routing criteria is an attribute of the request such as the primary key of the entity being accessed. Another common routing criteria is the customer type. For example, an application might provide paying customers with a higher SLA than free customers by routing their requests to a different set of servers with more capacity.",
	"Systems - Distributed - Theorems - CAP Theorem ": "In any distributed data store, you can have at most two of these three properties: consistency (C), high availability (A), tolerance to network partitions (P)",
	"Systems - Distributed - Theorems - CAP Theorem - Consistency (C)": "Consistency (C) – Every read receives the most recent write or an error.",
	"Systems - Distributed - Theorems - CAP Theorem - Availability (A)": "Availability (A) – Every request (read/write) gets a response, even if it's not the most recent data.",
	"Systems - Distributed - Theorems - CAP Theorem - PartitionTolerance (P)": "Partition Tolerance (P) – The system continues operating despite network failures between nodes.",
	"Systems - Distributed - Theorems - CAP Theorem - Solutions - CA - Forfeit Partitions": "The system achieves High Available Consistency. To manage data across multiple resources these systems used methods like 2-Phase Commit. Single-site databases, RDBMS (Oracle, Postgres, MySQL) could be good eamples of CA systems.",
	"Systems - Distributed - Theorems - CAP Theorem - Solutions - CP - Best Effort Availity": "The system achieves Strong Consistency with Partition Tolerance. Pessimistic Locking methods used for multi resource data management. DNS, MongoDB, HBase, Redis are the example CP systems.",
	"Systems - Distributed - Theorems - CAP Theorem - Solutions - AP - Best Effort Consistency": "The system offers Full Availability by relaxing consistency. Optimistic Locking methods used for multi resource data management. CouchBase, Cassandra, DynamoDB, Hazelcast are the example CP systems.",
	"Systems - Distributed - HashingFunction": "Traditionally how the data is distributed to all these nodes was using a hash function.",
	"Systems - Distributed - HashingFunction - PermanentHashing": "",
	"Systems - Distributed - HashingFunction - DistributedHashing": "Distributed hashing allows us to implement the hash table across multiple machines. A Distributed Hash Table(DHT) is a decentralized data store that allows us to store and retrieve data efficiently. The decentralized nature of the Distributed Hash Table allows all nodes to form the collective system without any centralized coordination.",
	"Systems - Distributed - HashingFunction - DistributedHashing - Properties - Decentralization": "All the nodes of the system collectively form the system without any central coordination.",
	"Systems - Distributed - HashingFunction - DistributedHashing - Properties - FaultTolerant": "The system is reliable(in some sense), with lots of nodes joining, leaving, and failing at all times.",
	"Systems - Distributed - HashingFunction - DistributedHashing - Properties - Scalable": "The system works efficiently with a large number of nodes.",
	"Systems - Distributed - HashingFunction - DistributedHashing - Limitations": "The scalability in the distributed hash table is static.",
	"Systems - Distributed - HashingFunction - ConsistentHashing": "Consistent hashing is a technique that works independently of the number of servers. One of the main goals of consistent hashing is to reduce data redistribution. Consistent hashing is a popular technique used in distributed systems to address the challenge of efficiently distributing keys or data elements across multiple nodes in a network. Consistent hashing’s primary objective is to reduce the number of remapping operations necessary when adding or removing nodes from the network, which contributes to the stability and dependability of the system. ",
	"Systems - Distributed - HashingFunction - ConsistentHashing - How": "Consistent hashing presents a crucial solution to the challenges of distributing data across nodes in distributed systems. By utilizing a hash ring structure and deterministic mapping algorithms, consistent hashing ensures that data is evenly spread across nodes, promoting efficient load balancing and fault tolerance.",
	"Systems - Distributed - HashingFunction - ConsistentHashing - Usage - Cassandra": "Apache Cassandra uses consistent hashing to distribute and replicate data efficiently across the cluster.",
	"Systems - Distributed - HashingFunction - ConsistentHashing - Usage - CDN": "Content Delivery Networks(CDN) distribute contents evenly across the edge servers using consistent hashing.",
	"Systems - Distributed - HashingFunction - ConsistentHashing - Usage - LoadBalancers": "Load Balancers use consistent hashing to distribute persistent connections across backend servers.",

	"Systems - Decentralized": "SECTION",
	"Systems - Decentralized - Theorems - DCS Theorem": "",
	"Systems - Decentralized - Theorems - DCS Theorem - Decentralization": "Decentralized means the system has no single point of failure or control (SPoF). Another way to state this is: if any single element is removed from {𝑆}, the system continues to perform its intended behavior, and no single component in {𝑆} has the power to redefine 𝑓𝑆 on its own.",
	"Systems - Decentralized - Theorems - DCS Theorem - Consensus": "Consensus means the system uses a collective decision-making process ('consensus algorithm') to update the system’s state, 𝑠, which is shared by all consensus participants. The result of the consensus algorithm determines the network’s accepted output of 𝑓𝑆 , and whether or not 𝑓𝑆 completes within 𝑆𝜏.",
	"Systems - Decentralized - Theorems - DCS Theorem - Scalability": "Scale means the system is capable of handling the transactional demands of any competing system providing the same service to the same arbitrary set of users across the globe (“at scale”).2"

}