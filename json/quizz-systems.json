{


	"Systems": "SECTION",
	"Systems - Theorems - CAP Theorem ": "In any distributed data store, you can have at most two of these three properties: consistency (C), high availability (A), tolerance to network partitions (P)",
	"Systems - Theorems - CAP Theorem - Consistency (C)": "Consistency (C) – Every read receives the most recent write or an error.",
	"Systems - Theorems - CAP Theorem - Availability (A)": "Availability (A) – Every request (read/write) gets a response, even if it's not the most recent data.",
	"Systems - Theorems - CAP Theorem - PartitionTolerance (P)": "Partition Tolerance (P) – The system continues operating despite network failures between nodes.",
	"Systems - Theorems - CAP Theorem - Solutions - CA - Forfeit Partitions": "The system achieves High Available Consistency. To manage data across multiple resources these systems used methods like 2-Phase Commit. Single-site databases, RDBMS (Oracle, Postgres, MySQL) could be good eamples of CA systems.",
	"Systems - Theorems - CAP Theorem - Solutions - CP - Best Effort Availity": "The system achieves Strong Consistency with Partition Tolerance. Pessimistic Locking methods used for multi resource data management. DNS, MongoDB, HBase, Redis are the example CP systems.",
	"Systems - Theorems - CAP Theorem - Solutions - AP - Best Effort Consistency": "The system offers Full Availability by relaxing consistency. Optimistic Locking methods used for multi resource data management. CouchBase, Cassandra, DynamoDB, Hazelcast are the example CP systems.",
	"Systems - Principles - Consistency": "In distributed systems, consistency models define how updates are seen across nodes.",
	"Systems - Principles - Consistency - Strong": "↳ Every read sees the latest write ↳ Higher latency, lower availability, higher integrity ↳ Ideal for real-time correctness",
	"Systems - Principles - Consistency - Sequential": "all processes see all memory operations in the same order.",
	"Systems - Principles - Consistency - Causal": "causally related operations are seen in the same order",
	"Systems - Principles - Consistency - Eventual": "↳ Reads may return stale data temporarily ↳ Lower latency, higher availability ↳ Great for scale-first systems .",
	"Systems - Principles - Consistency - Weak": "There might be inconsistent responses.",
	"Systems - Principles - HA - Scalability": "",
	"Systems - Principles - HA - Scalability - Dimensions": "In their book “The Art of Scalability,” Martin Abbott and Michael Fisher elaborate on the concept of the “scale cube,”. (X) Each service can then be further scaled by cloning (X-axis), (Y) The microservices pattern maps to the Y-axis of the cube, wherein functional decomposition is used to scale the system (Z) sharding (Z-axis).",
	"Systems - Principles - HA - Scalability - ScaleCube - X - clone services (horizontal duplication)": "X-axis scaling consists of running multiple copies of an application behind a load balancer. If there are N copies then each copy handles 1/N of the load. This is a simple, commonly used approach of scaling an application. One drawback of this approach is that because each copy potentially accesses all of the data, caches require more memory to be effective. Another problem with this approach is that it does not tackle the problems of increasing development and application complexity.",
	"Systems - Principles - HA - Scalability - ScaleCube - y - microservices (functional decomposition)": "Unlike X-axis and Z-axis, which consist of running multiple, identical copies of the application, Y-axis axis scaling splits the application into multiple, different services. Each service is responsible for one or more closely related functions. There are a couple of different ways of decomposing the application into services. One approach is to use verb-based decomposition and define services that implement a single use case such as checkout. The other option is to decompose the application by noun and create services responsible for all operations related to a particular entity such as customer management. An application might use a combination of verb-based and noun-based decomposition.",
	"Systems - Principles - HA - Scalability - ScaleCube - z - sharding databases (data partioning)": "When using Z-axis scaling each server runs an identical copy of the code. In this respect, it’s similar to X-axis scaling. The big difference is that each server is responsible for only a subset of the data. Some component of the system is responsible for routing each request to the appropriate server. One commonly used routing criteria is an attribute of the request such as the primary key of the entity being accessed. Another common routing criteria is the customer type. For example, an application might provide paying customers with a higher SLA than free customers by routing their requests to a different set of servers with more capacity.",
	"Systems - Principles - PartitionTolerance": "Partition tolerance means that the cluster continues to function even if there is a 'partition' (communication break) between two nodes (both nodes are up, but can't communicate).",

	"Systems - Centralized": "SECTION",
	"Systems - Centralized - Features - SinglePointControl": "Single Point of Control: All data processing and management tasks are handled by the central server. Easier to manage and maintain since there is one primary location for administration.",
	"Systems - Centralized - Features - Simplicity": "Simplified architecture with a clear structure where all operations are routed through the central node. Easy to deploy and manage due to centralized nature.",
	"Systems - Centralized - Features - Efficiency": "Efficient use of resources as the central server can be optimized for performance. Easier to implement security measures and updates centrally.",
	"Systems - Centralized - Features - ScalabilityIssues": "Limited scalability as the central server can become a bottleneck if the load increases significantly. Adding more clients can strain the server’s resources, leading to performance degradation.",
	"Systems - Centralized - Features - SinglePointFailure": "If the central server fails, the entire system can become inoperative. High availability and redundancy measures are essential to mitigate this risk.",

	"Systems - Distributed": "SECTION",
	"Systems - Distributed - Orchestration": "In orchestration, there is a central coordinator (often called an orchestrator) that controls the interaction between services.",
	"Systems - Distributed - Orchestration - Benefits - CentralizedControl": "Simplifies understanding and managing the workflow, as the orchestrator provides a single point of control.",
	"Systems - Distributed - Orchestration - Benefits - ErrorHandling": "Easier Error Handling: Error handling is a major part of many domain workflows, and it becomes easier. Retries if one or more domain services suffer from a short-term outage.",
	"Systems - Distributed - Orchestration - Benefits - VisibilityAndMonitoring": "It’s easier to monitor and log the process as it’s controlled from a central point.",
	"Systems - Distributed - Orchestration - Benefits - StateManagement": "Having an orchestrator makes the state of the workflow queriable, providing a place for other workflows and other transient states.",
	"Systems - Distributed - Orchestration - Drawbacks - SinglePointOfFailure": "The orchestrator can become a bottleneck and point of failure, impacting system resilience. (Redundancy can be added but with additional complexity)",
	"Systems - Distributed - Orchestration - Drawbacks - ScalabilityIssues": "The central orchestrator might become overwhelmed with traffic, limiting scalability. All communication must go through the mediator, creating a potential throughput bottleneck that can harm responsiveness.",
	"Systems - Distributed - Orchestration - Drawbacks - ComplexityAndCoupling": "This can lead to increased coupling between services and the orchestrator, hindering independent service scaling and evolution.",
	"Systems - Distributed - Orchestration - Drawbacks - FlexibilityLimitations": "Changes in workflow require changes in the orchestrator, potentially impacting all services involved.",
	"Systems - Distributed - LeaderElection": "Leader election is a critical concept in distributed system design, ensuring that a group of nodes can select a leader to coordinate and manage operations effectively.",
	"Systems - Distributed - LeaderElection - Leader": "In distributed systems, having a single leader can simplify decision-making and coordination, leading to more efficient and reliable operations.",
	"Systems - Distributed - LeaderElection - Algorithms": ".",
	"Systems - Distributed - LeaderElection - Algorithms - BullyAlgorithm": "The Bully Algorithm relies on a hierarchy of nodes where each node has a unique identifier, typically based on some ordering criterion such as IP address or node ID. The node with the highest identifier is considered the leader.",
	"Systems - Distributed - LeaderElection - Algorithms - RingAlgorithm": "The Ring Algorithm organizes nodes in a logical ring structure, where each node has knowledge of its successor node in the ring.",
	"Systems - Distributed - LeaderElection - Algorithms - Paxos": "Paxos is a consensus protocol designed to achieve agreement among a group of nodes, ensuring the selection of a single leader.",
	"Systems - Distributed - LeaderElection - Algorithms - Raft": "Raft is another consensus protocol designed for leader election and log replication in distributed systems, focusing on simplicity and understandability.",
	"Systems - Distributed - Examples - SpringCloud": "A set of tools for building cloud-native apps. Within Spring Cloud, several modules like Spring Cloud Netflix and Spring Cloud Kubernetes are used for microservices orchestration.",
	"Systems - Distributed - Examples - CDN": "Networks of distributed servers that deliver web content based on users’ geographic locations.",
	"Systems - Distributed - Examples - Kubernetes": "Kubernetes can orchestrate containerized Java applications. It automates the deployment, scaling, and management of containerized applications.",

	"Systems - Decentralized": "SECTION",
	"Systems - Decentralized - Choreography": "There’s no central point of control; instead, each service works independently, often based on events.",
	"Systems - Decentralized - Choreography - Benefits - Decentralization": "Reduces the risk of a single point of failure and avoids bottlenecks.",
	"Systems - Decentralized - Choreography - Benefits - Scalability": "Each service can scale independently, improving the system’s overall scalability.",
	"Systems - Decentralized - Choreography - Benefits - Flexibility": "Services can be updated, added, or removed with minimal impact on the overall system.",
	"Systems - Decentralized - Choreography - Benefits - Resilience": "The failure of a single service has less impact on the entire process.",
	"Systems - Decentralized - Choreography - Drawbacks - ComplexityMonitoringDebugging": "Tracing and understanding the workflow can be challenging due to the lack of a central control point.",
	"Systems - Decentralized - Choreography - Drawbacks - ErrorHandling": "Without central coordination, there’s a risk of redundant or conflicting actions.",
	"Systems - Decentralized - Choreography - Drawbacks - StateManagement": "No centralized state holder hinders ongoing state management.",
	"Systems - Decentralized - Choreography - Drawbacks - Recoverability": "Recoverability becomes more difficult without an orchestrator to attempt retries and other remediation efforts.",
	"Systems - Decentralized - Theorems - DCS Theorem": "",
	"Systems - Decentralized - Theorems - DCS Theorem - Decentralization": "Decentralized means the system has no single point of failure or control (SPoF). Another way to state this is: if any single element is removed from {𝑆}, the system continues to perform its intended behavior, and no single component in {𝑆} has the power to redefine 𝑓𝑆 on its own.",
	"Systems - Decentralized - Theorems - DCS Theorem - Consensus": "Consensus means the system uses a collective decision-making process ('consensus algorithm') to update the system’s state, 𝑠, which is shared by all consensus participants. The result of the consensus algorithm determines the network’s accepted output of 𝑓𝑆 , and whether or not 𝑓𝑆 completes within 𝑆𝜏.",
	"Systems - Decentralized - Theorems - DCS Theorem - Scalability": "Scale means the system is capable of handling the transactional demands of any competing system providing the same service to the same arbitrary set of users across the globe (“at scale”).",
	"Systems - Decentralized - Examples - MessageBrokers": ".",
	"Systems - Decentralized - Examples - P2PFileSharing": ".",
	"Systems - Decentralized - Examples - Blockchain": "."

}