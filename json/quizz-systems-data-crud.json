{

	"CRUD": "SECTION",
	"CRUD10": "https://www.linkedin.com/posts/nk-systemdesign-one_give-me-2-mins-and-ill-teach-you-how-a-database-activity-7312814148168437761-3GBJ/?utm_source=share&utm_medium=member_desktop&rcm=ACoAAABC9LwBrHjPW40o31rZRtAXH6eii8ctLzQ",
	"CRUD13": "https://www.linkedin.com/posts/sourabh-upadhyay-4597971aa_backend-interview-questions-activity-7315574997220052992-iC1k/?utm_source=share&utm_medium=member_android&rcm=ACoAAABC9LwBrHjPW40o31rZRtAXH6eii8ctLzQ",
	"CRUD20": "https://www.linkedin.com/posts/goyalshalini_behind-every-fast-query-smart-filter-or-activity-7333379018789933057-QmWv/?utm_source=share&utm_medium=member_android&rcm=ACoAAABC9LwBrHjPW40o31rZRtAXH6eii8ctLzQ",
	"CRUD24": "",
	"CRUD25": "",
	"CRUD26": "",
	"CRUD27": "",
	"CRUD28": "",
	"CRUD29": "",
	"CRUD30": "",

	"Querying": "SECTION",
	"Querying - Transactions": "https://medium.com/@patrickkoss/interview-so-how-do-you-do-a-transaction-with-nosql-databases-c3d80bc7d314",
	"Querying - Transactions - Principles - ACID": "ACID: Atomicity, Consistency, Isolation, Durability",
	"Querying - Transactions - Principles - ACID - Atomicity": "The DB must treat each transaction as all or nothing, if any part fails, the whole transaction must be rolled back as if it never happened.",
	"Querying - Transactions - Principles - ACID - Atomicity - Orthogonality": "Atomicity does not behave completely orthogonally with regard to the other ACID properties of transactions. For example, isolation relies on atomicity to roll back the enclosing transaction in the event of an isolation violation such as a deadlock; consistency also relies on atomicity to roll back the enclosing transaction in the event of a consistency violation by an illegal transaction. As a result of this, a failure to detect a violation and roll back the enclosing transaction may cause an isolation or consistency failure.",
	"Querying - Transactions - Principles - ACID - Consistency": "A catch-all term that means all the rules defined in the database must be followed when committing a transaction. The end state, at the end of the transaction, must be valid. Rules here can mean data constraints, cascades, triggers, etc. Consistency relies on atomicity, in that if there is a violation, we rely on the systems ability to roll back changes.",
	"Querying - Transactions - Principles - ACID - Isolation": "The isolation determines the visibility of changes made by one transaction for another transactions. Ideally, the result of 2 concurrent operations should be the same as if they occurred sequentially.",
	"Querying - Transactions - Principles - ACID - Isolation ": "https://medium.com/@patrickkoss/interview-so-how-do-you-do-a-transaction-with-nosql-databases-c3d80bc7d314",
	"Querying - Transactions - Principles - ACID - Isolation - Incosistencies": "Transaction isolation levels can lead to incoscient data reads. We can distinguish 3 types of these reads: Dirty, Phantom and NonRepeatable",
	"Querying - Transactions - Principles - ACID - Isolation - Incosistencies - States - DirtyRead ": "Uncommitted data is read.",
	"Querying - Transactions - Principles - ACID - Isolation - Incosistencies - States - NonRepeatableRead": "Transaction reads same row twice, and get a different values each time. Before transaction A is over, another transaction B also accesses the same data. Then, due to the modification caused by transaction B, the data read twice from transaction A may be different.",
	"Querying - Transactions - Principles - ACID - Isolation - Incosistencies - States - PhantomRead": "Two same queries retrieved different rows: When the user reads records, another transaction inserts or deletes rows to the records being read. When the user reads the same rows again, a new ‚Äúphantom‚Äù row will be found.",
	"Querying - Transactions - Principles - ACID - Isolation - Transactions": "A transaction is an unit of work that helps to respect ACID principle. This unit of work can only be executed entirely. It means that database will see zero (if transaction fails, operation called rollback) or all operations placed inside transaction (if transaction succeeds, operation called commit).",
	"Querying - Transactions - Principles - ACID - Isolation - Transactions - levels": "They're 4 mains transaction's isolation levels: read uncommited, read commited, repeatable read, serializable",
	"Querying - Transactions - Principles - ACID - Isolation - Transactions - levels - ReadUncommited": "Read Uncommitted is the lowest isolation level. In this level, one transaction may read not yet commited changes made by other transaction, thereby allowing dirty reads. In this level, transactions are not isolated from each other.",
	"Querying - Transactions - Principles - ACID - Isolation - Transactions - levels - ReadCommitted": "This isolation level guarantees that any data read is committed at the moment it is read. Thus it does not allows dirty read. The transaction hold a read or write lock on the current row, and thus prevent other rows from reading, updating or deleting it.",
	"Querying - Transactions - Principles - ACID - Isolation - Transactions - levels - RepeatableRead": "This is the most restrictive isolation level. The transaction holds read locks on all rows it references and write locks on all rows it inserts, updates, or deletes. Since other transaction cannot read, update or delete these rows, consequently it avoids non repeatable read.",
	"Querying - Transactions - Principles - ACID - Isolation - Transactions - levels - Serializable": "This is the Highest isolation level. A serializable execution is defined to be an execution of the operations of concurrently executing SQL-transactions that produces the same effect as some serial execution of those same SQL-transactions. A serial execution is one in which each SQL-transaction executes to completion before the next SQL-transaction begins.",
	"Querying - Transactions - Principles - ACID - Durability": "Transactions that have committed must survive permanently, even if the system crashes. This is usually assured by writing transactions into a log before acknowledging the commit. The log is on non-volatile storage and can be used to recreate the system state prior to failure (often automatically).",
	"Querying - Transactions - Principles - BASE": ".",
	"Querying - Transactions - Principles - BASE - ConsistencyModel": "BASE properties are looser than ACID. A BASE datastore values availability and scale, instead of guaranteed consistency. Used by NoSQL stores, including column family, key-value and document stores.",
	"Querying - Transactions - Principles - BASE - BasicAvailability": "The database appears to work most of the time.",
	"Querying - Transactions - Principles - BASE - SoftState": "Stores do not have to be write-consistent, nor do different replicas have to be mutually consistent all the time.",
	"Querying - Transactions - Principles - BASE - EventualConsistency": "Stores exhibit consistency at some later point (e.g., lazily at read time).",
	"Querying - Transactions - Principles - NewSQL": "https://levelup.gitconnected.com/newsql-databases-the-best-of-both-worlds-8727411a49ec",
	"Querying - Transactions - JTA": "Java Transaction API",
	"Querying - Transactions - XA": "XA is a two-phase commit protocol that is natively supported by many databases and transaction monitors.",
	"Querying - Transactions - TransactionalMonitor": "",

	"DataOptimization": "SECTION",
	"DataOptimization - Scaling - Archiving": "We implement archiving strategies to keep active data lean and fast, moving older data to separate storage.",
	"DataOptimization - Scaling - Replication": "Database replication copies and synchronizes database objects across multiple systems, enhancing availability, fault tolerance, and performance through redundancy.",
	"DataOptimization - Scaling - Replication - Types - MasterSlave": "Master writes, slaves replicate for reads.",
	"DataOptimization - Scaling - Replication - Types - MultiMaster": "Multiple nodes sync bidirectional writes.",
	"DataOptimization - Scaling - Replication - Types - Sync": "Transactions commit on all replicas.",
	"DataOptimization - Scaling - Replication - Types - Async": "Primary commits, then replicates asynchronously.",
	"DataOptimization - Scaling - Replication - Types - TransactionalReplication": "Real-time replication with order preservation.",
	"DataOptimization - Scaling - Replication - Types - SnapshotReplication": "Periodic full database copies distributed.",
	"DataOptimization - Scaling - Replication - Features - DataRedundancy": "Ensures copies of data exist across multiple locations.",
	"DataOptimization - Scaling - Replication - Features - AutomaticFailover": "Enables seamless recovery if a primary server fails.",
	"DataOptimization - Scaling - Replication - Features - LoadDistribution": "Spreads read/write operations across multiple servers.",
	"DataOptimization - Scaling - Replication - Features - RealTimeSynchronization": "Keeps replicas updated with minimal delay.",
	"DataOptimization - Scaling - Replication - Features - MultiSiteSupport": "Allows geographic distribution for disaster recovery.",
	"DataOptimization - Scaling - Replication - Technologies - MySQLReplication": "Native asynchronous master-slave replication.",
	"DataOptimization - Scaling - Replication - Technologies - PostgreSQLReplication": "Streaming Replication: Physical replication of write-ahead logs.",
	"DataOptimization - Scaling - Replication - Technologies - MongoDBReplicaSets": "Self-healing clusters with automatic failover.",
	"DataOptimization - Scaling - Replication - Technologies - SQLServerAlwaysOn": "High availability and disaster recovery solution.",
	"DataOptimization - Scaling - Sharding": "Database sharding is a technique where a large database is divided into smaller, independent parts called shards.",
	"DataOptimization - Scaling - Sharding - How": "Then stored on separate database servers",
	"DataOptimization - Scaling - Partitioning": "We use partitioning to break large tables into manageable chunks, improving query performance and simplifying maintenance.",
	"DataOptimization - Scaling - Partitioning - How": "The database system parses the incoming query and based on the partition key values it determines what partitions potentially contain the relevant data.",
	"DataOptimization - Scaling - Partitioning - Residing": "Both tables redides in the same database.",
	"DataOptimization - Scaling - Partitioning - Types - Horizontal": "Each partition contains a subset of the rows.",
	"DataOptimization - Scaling - Partitioning - Types - Vertical": "Each partition contains a subset of the columns.",
	"DataOptimization - Scaling - Vertical": "Upgrade your database server by adding more CPU, RAM, or storage to handle increased load.",
	"DataOptimization - Scaling - Caching": "Store frequently accessed data in-memory (e.g., Redis, Memcached) to reduce database load and improve response time.",
	"DataOptimization - Scaling - Indexing ": "A special data structure related to a database table and used for storing its important parts and enabling faster data search and retrieval. Indexes are especially efficient for large databases, where they significantly enhance query performance.",
	"DataOptimization - Scaling - Indexing - Unique": "Unique index ‚Äì doesn't allow duplicates in a table column and hence helps maintain data integrity.",
	"DataOptimization - Scaling - Indexing - Clustered": "Clustered index ‚Äì defines the physical order of records of a database table and performs data searching based on the key values. A table can have only one clustered index.",
	"DataOptimization - Scaling - Indexing - Non-clustered": "Non-clustered index ‚Äì keeps the order of the table records that don't match the physical order of the actual data on the disk. It means that the data is stored in one place and a non-clustered index ‚Äì in another one. A table can have multiple non-clustered indexes.",
	"DataOptimization - Scaling - Indexing - B-Tree": "B-trees, short for balanced trees, are the most common type of database index. A B-tree index is an ordered list of values divided into ranges. By associating a key with a row or range of rows, B-trees provide excellent retrieval performance for a wide range of queries, including exact match and range searches.",
	"DataOptimization - Scaling - Indexing - Bitmap": "In a bitmap index, the database stores a bitmap for each index key. In a conventional B-tree index, one index entry points to a single row. In a bitmap index, each index key stores pointers to multiple rows. Bitmap indexes are primarily designed for data warehousing or environments in which queries reference many columns in an ad hoc fashion.",
	"DataOptimization - Scaling - Indexing - HashIndex": "",
	"DataOptimization - Scaling - Indexing - Skiplist": "",
	"DataOptimization - Scaling - Indexing - Trie": "",
	"DataOptimization - Scaling - ConnectionPooling": "Opening and closing database connections has significant overhead. Reduce the overhead of opening/closing database connections by reusing existing ones, improving performance under heavy traffic.",
	"DataOptimization - Scaling - QueryOptimization": "Fine-tune SQL queries, eliminate expensive operations, and leverage indexes effectively to improve execution speed and reduce database load.",
	"DataOptimization - Design - Denormalization": "Optimize for querying (OLAP).",
	"DataOptimization - Design - Denormalization - Features - Pros": "Faster read operations, simpler queries.",
	"DataOptimization - Design - Denormalization - Features - Cons": "More redundancy, higher risk of data inconsistencies, harder maintenance.",
	"DataOptimization - Design - Denormalization - Methods - Redundancy": "Adding Redundant Data: Include extra copies of data to avoid complicated lookups..",
	"DataOptimization - Design - Denormalization - Methods - Aggregates": "Creating Aggregates: Store pre-calculated summary data to speed up queries.",
	"DataOptimization - Design - Denormalization - Methods - Combining": "Combining Tables: Merge related tables to simplify queries..",
	"DataOptimization - Design - Normalization": "Optimize for CRUDing (OLTP).",
	"DataOptimization - Design - Normalization - Features - Pros": "Better data integrity, less redundancy, easier maintenance.",
	"DataOptimization - Design - Normalization - Features - Cons": "Can slow down read operations due to multiple table joins.",
	"DataOptimization - Design - Normalization - Anomaly - Insert": "An insert anomaly occurs when you cannot add new data to the database without also adding irrelevant or redundant data. This typically happens in a poorly normalized table where some columns are dependent on others.",
	"DataOptimization - Design - Normalization - Anomaly - Delete": "A delete anomaly occurs when the deletion of a record results in the unintended loss of additional data that was associated with the record. This usually happens in a table where data is not properly normalized, causing related information to be removed inadvertently.",
	"DataOptimization - Design - Normalization - Anomaly - Update": "An update anomaly occurs when changes to data require multiple rows to be updated, leading to potential inconsistencies. This usually happens when the same piece of information is duplicated across multiple rows.",
	"DataOptimization - Design - Normalization - Forms - 1NF": "First Normal Form.",
	"DataOptimization - Design - Normalization - Forms - 1NF - Rule": "Ensure each column in a table contains unique and indivisible values.",
	"DataOptimization - Design - Normalization - Forms - 1NF - Reason": "This eliminates repeating groups and ensures that the data in each column is atomic, meaning that it cannot be divided further. It helps in simplifying the data structure and avoids the pitfalls of storing multiple values in a single column.",
	"DataOptimization - Design - Normalization - Forms - 1NF - Impact": "While 1NF ensures a basic level of data integrity by making data retrieval straightforward, it is not sufficient to handle more complex data dependencies and anomalies. Without further normalization, the database might still suffer from redundancy and update anomalies.",
	"DataOptimization - Design - Normalization - Forms - 2NF": "Second Normal Form.",
	"DataOptimization - Design - Normalization - Forms - 2NF - Rule": "Ensure all non-key columns are fully dependent on the entire primary key.",
	"DataOptimization - Design - Normalization - Forms - 2NF - Reason": "This addresses the issue of partial dependency, where non-key attributes are dependent on part of a composite primary key. It ensures that each non-key attribute is only dependent on the primary key, thus eliminating redundancy for non-key attributes.",
	"DataOptimization - Design - Normalization - Forms - 2NF - Impact": "By achieving 2NF, the database reduces redundancy and ensures that updates to the data are consistent. However, it might still face issues related to transitive dependencies, which are addressed in 3NF.",
	"DataOptimization - Design - Normalization - Forms - 3NF": "Third Normal Form.",
	"DataOptimization - Design - Normalization - Forms - 3NF - Rule": "Remove any columns that depend on non-key columns (transitive dependency).",
	"DataOptimization - Design - Normalization - Forms - 3NF - Reason": "This ensures that all attributes are only dependent on the primary key and not on other non-key attributes. It eliminates the potential for anomalies that can occur when non-key attributes are dependent on other non-key attributes.",
	"DataOptimization - Design - Normalization - Forms - 3NF - Impact": "3NF improves data integrity by ensuring that changes in non-key attributes do not lead to inconsistencies. It also enhances query performance by reducing the number of redundant data and simplifying the schema.",
	"DataOptimization - Design - Normalization - Forms - BCNF": "Boyce-Codd Normal Form (BCNF).",
	"DataOptimization - Design - Normalization - Forms - BCNF - Rule": "A stricter version of 3NF where every determinant must be a candidate key.",
	"DataOptimization - Design - Normalization - Forms - BCNF - Reason": "BCNF addresses situations where 3NF does not fully eliminate anomalies, particularly in cases where a table has multiple overlapping candidate keys.",
	"DataOptimization - Design - Normalization - Forms - BCNF - Impact": "Achieving BCNF further strengthens data integrity by ensuring that every determinant is a candidate key, thus removing any remaining anomalies and ensuring a more robust schema.",
	"DataOptimization - Design - Normalization - Forms - 4NF": "Fourth Normal Form.",
	"DataOptimization - Design - Normalization - Forms - 4NF - Rule": "Address even more complex dependencies, such as multi-valued dependencies.",
	"DataOptimization - Design - Normalization - Forms - 4NF - Reason": "These forms are designed to handle more complex scenarios that are not addressed by the earlier normal forms. For example, 4NF deals with multi-valued dependencies, ensuring that one attribute cannot have multiple independent multi-valued facts associated with it.",
	"DataOptimization - Design - Normalization - Forms - 4NF - Impact": "Higher normal forms provide even more stringent controls over data integrity and further reduce redundancy, though they are less commonly applied in everyday database design.",
	"DataOptimization - Design - Normalization - Forms - 5NF": "Fifth Normal Form.",
	"DataOptimization - Design - Normalization - Forms - 5NF - Rule": "A relation is said to be in 5FN if it is in 4FN and it cannot be further decomposed into smaller tables.",
	"DataOptimization - Design - Normalization - Forms - 5NF - Reason": ".",
	"DataOptimization - Design - Normalization - Forms - 5NF - Impact": ".",

	"DataModel": "SECTION",
	"DataModel - DataStructures": "https://medium.com/@ashishps/how-i-mastered-data-structures-and-algorithms-eb8c5273c56d",
	"DataModel - DataStructures - View": ".",
	"DataModel - DataStructures - MaterializedView": "We pre-compute and store complex query results, reducing processing time and resource usage. Think of it as caching for your most demanding queries.",
	"DataModel - DataStructures - DataTypes": ".",
	"DataModel - Types - SQL - RBDMS": "In a ùóøùó≤ùóπùóÆùòÅùó∂ùóºùóªùóÆùóπ ùó±ùóÆùòÅùóÆùóØùóÆùòÄùó≤, data is organized in rows and columns where a row represents a record and its data fields are stored in columns. They are ideal for when ACID compliance is required, and a predefined schema can be created.",
	"DataModel - Types - SQL - RBDMS - MySQL": "",
	"DataModel - Types - SQL - RBDMS - PostgresSQL": "",
	"DataModel - Types - SQL - InMemoryDB": "Stores entire data in RAM for extremely fast access. Useful for applications requiring ultra-low latency and high-speed caching layer.",
	"DataModel - Types - SQL - InMemoryDB - Redis": "for caching and real-time data processing. https://www.linkedin.com/posts/alexandre-zajac_softwareengineering-systemdesign-programming-activity-7315273057915289600-XxIa/?utm_source=share&utm_medium=member_android&rcm=ACoAAABC9LwBrHjPW40o31rZRtAXH6eii8ctLzQ",
	"DataModel - Types - SQL - InMemoryDB - Memcache": "for high-performance distributed memory object caching.",
	"DataModel - Types - SQL - NewSQL": "Scalable SQL + consistency",
	"DataModel - Types - SQL - NewSQL - Techniques - Coordination": "Distributed transaction coordination",
	"DataModel - Types - SQL - NewSQL - Techniques - MVCC": "MVCC (Multi-Version Concurrency Control)",
	"DataModel - Types - SQL - NewSQL - Techniques - 2PC": "Two-phase commit",
	"DataModel - Types - SQL - NewSQL - Techniques - InMemory": "In-memory processing",
	"DataModel - Types - SQL - NewSQL - Techniques - Automatic": "Automatic partitioning (sharding)",
	"DataModel - Types - SQL - NewSQL - Tools - MySQLNDBCluster": "Built for strong consistency / Shared-nothing architecture / Automatic partitioning across nodes / Synchronous replication / Great for SQL-style queries and mission-critical ops",
	"DataModel - Types - SQL - NewSQL - Tools - TIBCOActiveSpaces": "An in-memory data grid / Focused on raw throughput / Great at batch ingestion / Sacrifices relational constraints for speed / Not built for cross-region active-active setups",
	"DataModel - Types - SQL - NewSQL - Tools - GoogleSpanner": "for combining NoSQL scalability with traditional RDBMS features",
	"DataModel - Types - SQL - NewSQL - Tools - CockroachDB": "for distributed SQL.",
	"DataModel - Types - NoSQL - Column": "Stores data in flexible columns to optimize reading a specific attribute. Useful for applications dealing with high write throughput and running analytical queries.",
	"DataModel - Types - NoSQL - Column - BigQuery": "",
	"DataModel - Types - NoSQL - Column - Cassandra": "",
	"DataModel - Types - NoSQL - XML": ".",
	"DataModel - Types - NoSQL - XML - Tamino": ".",
	"DataModel - Types - NoSQL - XML - eXis-db": ".",
	"DataModel - Types - NoSQL - Document": "Stores data in flexible, semi-structured document formats like JSON or BSON. Useful for unstructured, hierarchical or rapidly changing data.",
	"DataModel - Types - NoSQL - Document - MongoDB": "",
	"DataModel - Types - NoSQL - Document - CouchDB": "",
	"DataModel - Types - NoSQL - Graph": "Stores data as nodes and edges. Used to represent complex relationships like recommendation engines and social networks.",
	"DataModel - Types - NoSQL - Graph - Neo4J": "",
	"DataModel - Types - NoSQL - Graph - Neptune": "",
	"DataModel - Types - NoSQL - KeyValueStores": "Stores data as key-value pairs for fast retrieval and high scalability. - Ideal for applications dealing with high-volume of data and requiring fast lookups by key..",
	"DataModel - Types - NoSQL - KeyValueStores - Redis": "",
	"DataModel - Types - NoSQL - KeyValueStores - DynamoDB": "",
	"DataModel - Types - Specialized": "",
	"DataModel - Types - Specialized - Vector": "ùó©ùó≤ùó∞ùòÅùóºùóø ùó±ùóÆùòÅùóÆùóØùóÆùòÄùó≤ùòÄ store data as vectors, enabling fast similarity searches for high-dimensional data. They are ideal for AI & ML applications, such as recommendations and searching unstructured data like images, text, or audio.",
	"DataModel - Types - Specialized - Vector - Milvus": "",
	"DataModel - Types - Specialized - Vector - Pinecone": "",
	"DataModel - Types - Specialized - TimeSeriesDB": "Optimized for storing and querying time-stamped data. Useful when data is generated in chronological order like monitoring systems and financial data.",
	"DataModel - Types - Specialized - TimeSeriesDB - InfluxDB": "for time-stamped data like logs and metrics",
	"DataModel - Types - Specialized - TimeSeriesDB - TimescaleDB": "extension for PostgreSQL.",
	"DataModel - Types - Specialized - TimeSeriesDB - Prometheus": ".",
	"DataModel - Types - Specialized - SpatialDB": "Designed to store and query location-based data. Ideal for supporting location based features like in ride-hailing services and mapping applications. GIS, mapping ",
	"DataModel - Types - Specialized - SpatialDB - ùòóùò∞ùò¥ùòµùòéùòêùòö": "",
	"DataModel - Types - Specialized - SpatialDB - ùòñùò≥ùò¢ùò§ùò≠ùò¶ ùòöùò±ùò¢ùòµùò™ùò¢ùò≠": "",
	"DataModel - Types - Niche": "",
	"DataModel - Types - Niche - ObjectOriented": "Align with code structure",
	"DataModel - Types - Niche - ObjectOriented - ùòñùò£ùò´ùò¶ùò§ùòµùòãùòâ": "",
	"DataModel - Types - Niche - ObjectOriented - ùò•ùò£4ùò∞": "",
	"DataModel - Types - Niche - BlockchainDB": "Immutability, trust ",
	"DataModel - Types - Niche - TestSearch": "Optimized for storing, indexing and searching text data. Used for content-heavy applications requiring text search, filtering and ranking like search engines.",
	"DataModel - Types - Niche - TestSearch - ElasticSearch": "",
	"DataModel - Types - Niche - TestSearch - Solr": "",
	"DataModel - Types - Niche - BlobStore": "Optimized for storing and retrieving large objects like images and videos. Useful when you want scalable and low-cost storage for rarely accessed data. Typically paired with a CDN to reduce latency for end users.",
	"DataModel - Types - Niche - BlobStore - AmazonS3": "",
	"DataModel - Types - Niche - BlobStore - GoogleCloudStorage": "",
	"DataModel - Types - Niche - BlobStore - AzureBlobStorage": "",
	"DataModel - ID - UUID": "A UUID (Universally Unique Identifier) is a 128-bit number used to uniquely identify objects or records in computer systems. There are multiple versions of UUIDs.",
	"DataModel - ID - UUID - unique": "UUIDs are not guaranteed to be unique, instead they are given a certain (typically very low) probability of collision. The probability of generating two UUIDs (especially v4 or v7) that collide is very low, but not zero.",
	"DataModel - ID - UUIDv1 - Time-based": "A combination of the current timestamp and the MAC address of the machine, unique but may expose hardware information.",
	"DataModel - ID - UUIDv2 - DCE Security": "Similar to Version 1 but includes POSIX UID/GID information, for applications requiring user or group identification.",
	"DataModel - ID - UUIDv3 - Name-based, MD5": "Hashes a namespace identifier and a name using the MD5 algorithm, producing consistent UUIDs for the same input data.",
	"DataModel - ID - UUIDv4 - Random": "Uses random numbers, offering simplicity and a low probability of duplication. e942bbe9-afdc-4c62-a438-4efee77954b3 You can tell it‚Äôs UUIDv4 because the digit ‚Äò4‚Äô appears in the 13th position. This is a key identifier for the version of the UUID.",
	"DataModel - ID - UUIDv5 - Name-based, SHA-1": "Similar to Version 3 but uses the SHA-1 hashing algorithm, providing a more secure hash function for generating UUIDs from names.",
	"DataModel - ID - UUIDv6 - Ordered Time-based": "A reordering of Version 1 UUIDs to improve database indexing by placing the timestamp in the most significant bits, facilitating chronological ordering. May be suitable for some use cases of database keys needing ordering.",
	"DataModel - ID - UUIDv7 - Unix Epoch Timestamp": "Encodes a Unix timestamp with millisecond precision in the most significant 48 bits, followed by random data, ensuring uniqueness and time-ordering. 01922e13-43f2-79ef-ab97-ca7a7d021d34 UUIDv7 is a time-based version of UUID, meaning that the identifiers are generated in an increasing order.",
	"DataModel - ID - UUIDv7 - ordered": "Because the UUIDs are time-based, they are ordered, which leads to better indexing performance compared to the randomness of UUIDv4.",
	"DataModel - ID - UUIDv8 - Custom": "Reserved for custom implementations, allowing for the inclusion of application-specific data within the UUID structure.",
	"DataModel - ID - ULID": "Universally Unique Lexicographically Sortable Identifier. ULID is a UUID alternative that is also globally unique, but with the added benefit of being lexicographically sortable.",
	"DataModel - ID - Auto-IncrementingIDs": ".",
	"DataModel - ID - SnowflakeID": "Twitter. A distributed ID generation algorithm that generates 64-bit unique IDs using a combination of a timestamp, machine ID, and sequence number.",
	"DataModel - ID - KSUID": "KSUID (K-Sortable Unique Identifier). KSUIDs are a variation of UUIDs that include a timestamp, making them sortable by creation time. A 27-character string consisting of a timestamp and randomly generated bits, ensuring k-sortability.",
	"DataModel - ID - NanoID": "NanoID is a small, fast, and secure alternative to UUID, designed to be URL-friendly and customizable in terms of size. A short, random, URL-friendly string with customizable length and alphabet.",
	"DataModel - ID - RandomHash-BasedID": "Random Hash-Based ID (SHA-256 or MD5 Hashing). Randomly generated strings using hash functions like SHA-256 or MD5 to create unique identifiers. A fixed-length 32- or 64-character string generated by hashing data (like a combination of timestamp and user data).",
	"DataModel - ID - ObjectID": "ObjectID (MongoDB ObjectID). MongoDB‚Äôs ObjectID (BSON binary JSON) is a 12-byte unique identifier that includes a timestamp, machine identifier, process identifier, and a counter.",
	"DataModel - ID - CUID2": "CUID2 (Collision-Resistant Unique Identifier). Cuid2 is designed to minimize the likelihood of collision in distributed systems, providing a URL-safe, human-readable, and collision-resistant ID.",
	"DataModel - ID - FlakeID": "Includes a timestamp, machine identifier, and sequence number. If you require unique, time-ordered identifiers for easier sorting and debugging. Example: 304857642123456",
	"DataModel - ID - Time-basedIDs": "Often a Unix timestamp concatenated with random bits or other unique data. Where chronological order is important, such as logging or event tracking.",
	"DataModel - ID - SequentialGUIDs": "A GUID optimized for indexing, often beginning with a time-ordered segment. Where GUIDs are necessary, but ordered indexing is needed for better database performance. Example: 6E4F6A80-4F64-11EE-B4FA-0242AC120002",
	"DataModel - ID - ShortID": "Generates a compact, unique alphanumeric string, often used in URLs. URL shortening or user-friendly identifiers in public URLs. Example: 2K5czP8",
	"DataModel - ID - ZUID": "ZUID (Zero-width Unique Identifier): Involves zero-width characters (e.g., zero-width spaces) that are invisible but can be parsed for uniqueness. If you need invisible identifiers for tracking or metadata without impacting visual layout. Example: Internally may look like \u200B\u200C\u200D"

}